<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Machine learning needs data – NLP: From Simple to Spectacular</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../references.html" rel="next">
<link href="../intro.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../01_data/data.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Machine learning needs data</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">NLP: From Simple to Spectacular</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduction</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../01_data/data.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Machine learning needs data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#quality-vs.-quantity" id="toc-quality-vs.-quantity" class="nav-link active" data-scroll-target="#quality-vs.-quantity"><span class="header-section-number">1.1</span> Quality vs.&nbsp;quantity</a></li>
  <li><a href="#getting-the-data" id="toc-getting-the-data" class="nav-link" data-scroll-target="#getting-the-data"><span class="header-section-number">1.2</span> Getting the data</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview"><span class="header-section-number">1.2.1</span> Overview</a></li>
  <li><a href="#dataset-specifics" id="toc-dataset-specifics" class="nav-link" data-scroll-target="#dataset-specifics"><span class="header-section-number">1.2.2</span> Dataset specifics</a></li>
  <li><a href="#directory-structure" id="toc-directory-structure" class="nav-link" data-scroll-target="#directory-structure"><span class="header-section-number">1.2.3</span> Directory structure</a></li>
  </ul></li>
  <li><a href="#question-the-dataset" id="toc-question-the-dataset" class="nav-link" data-scroll-target="#question-the-dataset"><span class="header-section-number">1.3</span> Question the dataset</a>
  <ul class="collapse">
  <li><a href="#cleaning-the-data" id="toc-cleaning-the-data" class="nav-link" data-scroll-target="#cleaning-the-data"><span class="header-section-number">1.3.1</span> Cleaning the data</a></li>
  <li><a href="#train-test-contamination" id="toc-train-test-contamination" class="nav-link" data-scroll-target="#train-test-contamination"><span class="header-section-number">1.3.2</span> Train-test contamination</a></li>
  </ul></li>
  <li><a href="#reflection" id="toc-reflection" class="nav-link" data-scroll-target="#reflection"><span class="header-section-number">1.4</span> Reflection</a>
  <ul class="collapse">
  <li><a href="#keep-asking-why" id="toc-keep-asking-why" class="nav-link" data-scroll-target="#keep-asking-why"><span class="header-section-number">1.4.1</span> Keep asking “why?”</a></li>
  </ul></li>
  <li><a href="#unsupervised-learning-data" id="toc-unsupervised-learning-data" class="nav-link" data-scroll-target="#unsupervised-learning-data"><span class="header-section-number">1.5</span> Unsupervised learning data</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Machine learning needs data</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>Without data, machine learning is nothing. After all what will it learn if it has nothing to learn from. Think about everything you’ve learned throughout your life. All the books you’ve read, the movies you’ve watched, the experiences you’ve lived. Everything you’ve touched, tasted, heard, felt, smelled. It all comes together to shape who you are and what you know. Our brains adapt and change to all of this input. Our brains <em>learn</em>. Take away all of the memories and experiences and what are we left with? Thoughts maybe, but of what? Without the context of our life there isn’t much to think about. Machine learning models work kind of like our brain, but much simpler. They take data and try to make sense of it, or <em>learn</em> from it. The more data, the easier it is to learn from, at least in theory.</p>
<section id="quality-vs.-quantity" class="level2 page-columns page-full" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="quality-vs.-quantity"><span class="header-section-number">1.1</span> Quality vs.&nbsp;quantity</h2>
<p>While we will dive into many algorithms over the course of this book, I want to drive home that machine learning models <em>need</em> data to learn. We can have the fanciest neural network on the best GPU cluster in the world, but without data, it’s all pointless. To drive this point home let’s see some machine learning in action.</p>
<p>We’ll start with a line. Nothing special, just the equation <code>y = x</code>.</p>
<div id="c4a0b951-9d1e-4856-aa10-4fe2d903bba4" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-2"><a href="#cb1-2"></a>sns.set_theme(style<span class="op">=</span><span class="st">'darkgrid'</span>)</span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a>x <span class="op">=</span> y <span class="op">=</span> [<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>]</span>
<span id="cb1-5"><a href="#cb1-5"></a>_ <span class="op">=</span> sns.lineplot(x<span class="op">=</span>x, y<span class="op">=</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="data_files/figure-html/cell-2-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="page-columns page-full"><p>This line is the ground truth. It is real. But let’s imagine we don’t have the line. We just have a couple random points on the line.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">I love <a href="https://seaborn.pydata.org/"><code>seaborn</code></a> for rapid data visualization. It can’t do everything perfectly, but it does the common things beautifully.</span></div></div>
<div id="7856c388-a970-4c9a-8501-0e22015f7517" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1"></a><span class="im">import</span> random</span>
<span id="cb2-2"><a href="#cb2-2"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb2-3"><a href="#cb2-3"></a></span>
<span id="cb2-4"><a href="#cb2-4"></a>random.seed(<span class="dv">100392</span>)</span>
<span id="cb2-5"><a href="#cb2-5"></a></span>
<span id="cb2-6"><a href="#cb2-6"></a><span class="kw">def</span> random_x(n):</span>
<span id="cb2-7"><a href="#cb2-7"></a>    <span class="co">"""Return `n` random values from -1 to 1."""</span></span>
<span id="cb2-8"><a href="#cb2-8"></a>    <span class="cf">return</span> [random.uniform(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>) <span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(n)]</span>
<span id="cb2-9"><a href="#cb2-9"></a></span>
<span id="cb2-10"><a href="#cb2-10"></a>xs <span class="op">=</span> ys <span class="op">=</span> random_x(<span class="dv">2</span>)</span>
<span id="cb2-11"><a href="#cb2-11"></a>_ <span class="op">=</span> sns.scatterplot(x<span class="op">=</span>xs, y<span class="op">=</span>ys)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="data_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Visually, we could draw a line from dot to dot and we’d get the same line in the previous plot. But we’re not interested in figuring out the line ourselves. We’re here to have machine learning do it for us. This is already integrated into <code>seaborn</code> so there’s not much code for us to write. The <a href="https://seaborn.pydata.org/generated/seaborn.regplot.html"><code>regplot</code></a> function will plot our data points and use machine learning to fit a line to those data points.</p>
<div id="28aacf5f-c69e-428f-9fdf-482b3e1ac88c" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>_ <span class="op">=</span> sns.regplot(x<span class="op">=</span>xs, y<span class="op">=</span>ys, truncate<span class="op">=</span><span class="va">False</span>, ci<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="data_files/figure-html/cell-4-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Will you look at that! The line was perfectly predicted based on the data points.</p>
<div class="page-columns page-full"><p>But real world data isn’t this simple or this <em>clean</em>. There’s usually some amount of noise in the data that can affect the quality of predictions.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Noise is randomness introduced to the data. It can come from many places like imprecise measurements, mislabelling, or unaccounted variables to name a few.</span></div></div>
<p>Now let’s imagine we don’t have points on the line, but points close to the line. How will this change the predicted line?</p>
<div id="fc1c37b7-49af-4b13-819b-1b95eef6a831" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a><span class="co"># Add noise to the data points to simulate noisy data.</span></span>
<span id="cb4-2"><a href="#cb4-2"></a><span class="kw">def</span> noisy_process(xs, noise):</span>
<span id="cb4-3"><a href="#cb4-3"></a>    <span class="co">"""Return noisy values of `xs`."""</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>    <span class="cf">return</span> [x <span class="op">+</span> random.uniform(<span class="op">-</span>noise, noise) <span class="cf">for</span> x <span class="kw">in</span> xs]</span>
<span id="cb4-5"><a href="#cb4-5"></a></span>
<span id="cb4-6"><a href="#cb4-6"></a>ys_noisy <span class="op">=</span> noisy_process(xs, <span class="fl">.25</span>)</span>
<span id="cb4-7"><a href="#cb4-7"></a></span>
<span id="cb4-8"><a href="#cb4-8"></a>ax <span class="op">=</span> sns.regplot(x<span class="op">=</span>xs, y<span class="op">=</span>ys, truncate<span class="op">=</span><span class="va">False</span>, ci<span class="op">=</span><span class="va">False</span>, scatter_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.5</span>})</span>
<span id="cb4-9"><a href="#cb4-9"></a>_ <span class="op">=</span> sns.regplot(x<span class="op">=</span>xs, y<span class="op">=</span>ys_noisy, truncate<span class="op">=</span><span class="va">False</span>, ci<span class="op">=</span><span class="va">False</span>, ax<span class="op">=</span>ax, scatter_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.5</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="data_files/figure-html/cell-5-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div class="page-columns page-full"><p>Hmm, that doesn’t look so bad. The predicted line in orange is pretty close to the real line in blue and has the same slope. But what if we just got lucky and the random noise happened to be low? Maybe we should run it a few more times to be sure.</p><div class="no-row-height column-margin column-container"><span class="margin-aside"><code>pandas</code> is another great library we’ll use over and over again. We’ll get to more on that later.</span></div></div>
<div id="9e6f27d3-159b-4a50-b4e0-27c01ec05c68" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb5-2"><a href="#cb5-2"></a></span>
<span id="cb5-3"><a href="#cb5-3"></a><span class="kw">def</span> simulate_n(n, n_points, noise):</span>
<span id="cb5-4"><a href="#cb5-4"></a>    <span class="co">"""Return a `pd.DataFrame` with `n` separate simulations of `n_points`."""</span></span>
<span id="cb5-5"><a href="#cb5-5"></a>    data <span class="op">=</span> []</span>
<span id="cb5-6"><a href="#cb5-6"></a>    <span class="cf">for</span> x <span class="kw">in</span> [<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>]:</span>
<span id="cb5-7"><a href="#cb5-7"></a>        data.append({<span class="st">'x'</span>: x, <span class="st">'y'</span>: x, <span class="st">'simulation'</span>: <span class="st">'Ground Truth'</span>, <span class="st">'noise'</span>: noise})</span>
<span id="cb5-8"><a href="#cb5-8"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(n):</span>
<span id="cb5-9"><a href="#cb5-9"></a>        xs <span class="op">=</span> random_x(n_points)</span>
<span id="cb5-10"><a href="#cb5-10"></a>        ys <span class="op">=</span> noisy_process(xs, noise)</span>
<span id="cb5-11"><a href="#cb5-11"></a>        <span class="cf">for</span> x, y <span class="kw">in</span> <span class="bu">zip</span>(xs, ys):</span>
<span id="cb5-12"><a href="#cb5-12"></a>            data.append(</span>
<span id="cb5-13"><a href="#cb5-13"></a>                {<span class="st">'x'</span>: x, <span class="st">'y'</span>:y, <span class="st">'simulation'</span>: i<span class="op">+</span><span class="dv">1</span>, <span class="st">'noise'</span>:noise}</span>
<span id="cb5-14"><a href="#cb5-14"></a>            )</span>
<span id="cb5-15"><a href="#cb5-15"></a>    <span class="cf">return</span> pd.DataFrame(data)</span>
<span id="cb5-16"><a href="#cb5-16"></a></span>
<span id="cb5-17"><a href="#cb5-17"></a>df <span class="op">=</span> simulate_n(<span class="dv">4</span>, <span class="dv">2</span>, <span class="fl">0.25</span>)</span>
<span id="cb5-18"><a href="#cb5-18"></a><span class="co"># `lmplot` is a fancier version of `regplot` that can handle multiple</span></span>
<span id="cb5-19"><a href="#cb5-19"></a><span class="co"># lines.</span></span>
<span id="cb5-20"><a href="#cb5-20"></a>_ <span class="op">=</span> sns.lmplot(df, x<span class="op">=</span><span class="st">"x"</span>, y<span class="op">=</span><span class="st">'y'</span>, ci<span class="op">=</span><span class="va">False</span>, hue<span class="op">=</span><span class="st">'simulation'</span>, truncate<span class="op">=</span><span class="va">False</span>, scatter_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.5</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="data_files/figure-html/cell-6-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Most of these look pretty close to the blue line, the ground truth, but what’s going on with simulation 4? The noise confused the machine learning model. It only has two points to work with and given two points it can figure out a line that perfectly lies on those two points. These two points imperfectly represent the real line and so the machine learned the line of this imperfect representation. And it gets worse with more noise.</p>
<div id="accd66e7-c505-49b1-a7ed-f9754905cf05" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>df <span class="op">=</span> pd.concat([simulate_n(<span class="dv">4</span>, <span class="dv">2</span>, noise) <span class="cf">for</span> noise <span class="kw">in</span> [<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="dv">1</span>]])</span>
<span id="cb6-2"><a href="#cb6-2"></a>_ <span class="op">=</span> sns.lmplot(df, x<span class="op">=</span><span class="st">'x'</span>,y<span class="op">=</span><span class="st">'y'</span>, ci<span class="op">=</span><span class="va">False</span>, hue<span class="op">=</span><span class="st">'simulation'</span>, truncate<span class="op">=</span><span class="va">False</span>, col<span class="op">=</span><span class="st">'noise'</span>, scatter_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.5</span>},facet_kws<span class="op">=</span>{<span class="st">'xlim'</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="st">'ylim'</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="data_files/figure-html/cell-7-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>Yup, that’s a mess. But there is a way to learn from noisy data, you just need more of it. Let’s try a hundred points per simulation.</p>
<div id="1d022a47-28ff-443b-a955-f6a6875f58d9" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>df <span class="op">=</span> pd.concat([simulate_n(<span class="dv">4</span>, <span class="dv">100</span>, noise) <span class="cf">for</span> noise <span class="kw">in</span> [<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="dv">1</span>]])</span>
<span id="cb7-2"><a href="#cb7-2"></a>_ <span class="op">=</span> sns.lmplot(df, x<span class="op">=</span><span class="st">'x'</span>,y<span class="op">=</span><span class="st">'y'</span>, ci<span class="op">=</span><span class="va">False</span>, hue<span class="op">=</span><span class="st">'simulation'</span>, truncate<span class="op">=</span><span class="va">False</span>, col<span class="op">=</span><span class="st">'noise'</span>, scatter_kws<span class="op">=</span>{<span class="st">'alpha'</span>: <span class="fl">0.5</span>},facet_kws<span class="op">=</span>{<span class="st">'xlim'</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="st">'ylim'</span>:(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>)})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="data_files/figure-html/cell-8-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>That’s night and day compared to two data points. Even when <code>noise = 1.0</code> the machine learning model does a good job of finding the line. This is because there’s more information to learn from and the machine learning model can separate the noise and zero in on the truth.</p>
<p>The lesson here is data quality is important, but so is data <em>quantity</em>. Sometimes the answer is a better machine learning model, but that’s not always true, you might just need more data.</p>
</section>
<section id="getting-the-data" class="level2 page-columns page-full" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="getting-the-data"><span class="header-section-number">1.2</span> Getting the data</h2>
<p>Our models will be using a dataset of movie reviews from IMDB <span class="citation" data-cites="maas-EtAl:2011:ACL-HLT2011">(<a href="../references.html#ref-maas-EtAl:2011:ACL-HLT2011" role="doc-biblioref">Maas et al. 2011</a>)</span>. There are several ways to get your hands on a dataset, you can curate them yourself or rely on the work of others. This dataset can be found at <a href="https://ai.stanford.edu/~amaas/data/sentiment">https://ai.stanford.edu/~amaas/data/sentiment</a>, but for simplicities sake it’s downloadable from this github repo.</p>
<p>Let’s grab the data!</p>
<div id="87b50502-6d27-407a-bec6-90f809ae122f" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1"></a><span class="im">import</span> tarfile</span>
<span id="cb8-2"><a href="#cb8-2"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb8-3"><a href="#cb8-3"></a></span>
<span id="cb8-4"><a href="#cb8-4"></a><span class="im">import</span> requests</span>
<span id="cb8-5"><a href="#cb8-5"></a></span>
<span id="cb8-6"><a href="#cb8-6"></a>tar_path <span class="op">=</span> Path(<span class="st">'aclImdb_v1.tar.gz'</span>)</span>
<span id="cb8-7"><a href="#cb8-7"></a><span class="cf">if</span> <span class="kw">not</span> tar_path.exists():</span>
<span id="cb8-8"><a href="#cb8-8"></a>    r <span class="op">=</span> requests.get(<span class="st">'https://github.com/spenceforce/NLP-Simple-to-Spectacular/releases/download/aclImdb_dataset/aclImdb_v1.tar.gz'</span>, stream<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb8-9"><a href="#cb8-9"></a>    <span class="cf">with</span> tar_path.<span class="bu">open</span>(<span class="st">'wb'</span>) <span class="im">as</span> f:</span>
<span id="cb8-10"><a href="#cb8-10"></a>        <span class="cf">for</span> chunk <span class="kw">in</span> r.iter_content(chunk_size<span class="op">=</span><span class="dv">128</span>):</span>
<span id="cb8-11"><a href="#cb8-11"></a>            f.write(chunk)</span>
<span id="cb8-12"><a href="#cb8-12"></a></span>
<span id="cb8-13"><a href="#cb8-13"></a><span class="cf">with</span> tarfile.<span class="bu">open</span>(tar_path) <span class="im">as</span> tar:</span>
<span id="cb8-14"><a href="#cb8-14"></a>    tar.extractall(<span class="bu">filter</span><span class="op">=</span><span class="st">'data'</span>)</span>
<span id="cb8-15"><a href="#cb8-15"></a>    data_path <span class="op">=</span> Path(<span class="st">'aclImdb'</span>)</span>
<span id="cb8-16"><a href="#cb8-16"></a>    <span class="co"># The untarred directory is `aclImdb` instead of `aclImdb_v1`.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="page-columns page-full"><p>This extracts the data from the tarball then assigns the output directory as a <code>pathlib.Path</code> object to <code>data_path</code>.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">I highly recommend checking out the <a href="https://docs.python.org/3/library/pathlib.html">pathlib</a> library if you don’t already use it. It provides a nice object oriented API for handling file paths.</span></div></div>
<div class="page-columns page-full"><p>There are a lot of datasets out there. Some better than others. Before trying to predict anything, it’s a good idea to get a sense of what the dataset actually contains. Hopefully the datasets you’re using are well documented. The dataset we’re working with comes with a README which we can see in the directory contents.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Don’t worry if the paths shown in this notebook are different from the ones you see on your compute resource. The structure of the data directory should be the same, and by leveraging relative paths with <code>Path</code> objects, everything should just work.</span></div></div>
<div id="2d9fdd64-8b1e-4274-a067-798d8570c793" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="bu">list</span>(data_path.iterdir())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>[PosixPath('aclImdb/imdbEr.txt'),
 PosixPath('aclImdb/README'),
 PosixPath('aclImdb/train'),
 PosixPath('aclImdb/imdb.vocab'),
 PosixPath('aclImdb/test')]</code></pre>
</div>
</div>
<p>If you’re working through this notebook in jupyter, I recommend taking a pause and reading the README yourself.</p>
<p>I’ll summarize the main takeaways here for those of you reading this online.</p>
<section id="overview" class="level3" data-number="1.2.1">
<h3 data-number="1.2.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">1.2.1</span> Overview</h3>
<p>This dataset contains movie reviews and labels indicating if the review is positive (label 1) or negative (label 0). It is intended for benchmarking sentiment classification tasks. Sentiment classification is about predicting the feeling a text conveys. Like emotions such as happy, sad, or angry. In this case it’s predicting whether a review says if a movie is good or bad.</p>
</section>
<section id="dataset-specifics" class="level3" data-number="1.2.2">
<h3 data-number="1.2.2" class="anchored" data-anchor-id="dataset-specifics"><span class="header-section-number">1.2.2</span> Dataset specifics</h3>
<p>There are 50k reviews, split into two groups of 25k. One group is for training machine learning models and the other is for testing them. Within each group of 25k, the reviews are split into half positive and half negative.</p>
<p>There’s at most 30 reviews for a given movie. The train and test sets have reviews for different movies, so none of the movies reviewed in the train set show up in the test set. Negative reviews have a score of 4 or less and positive reviews have a score of 7 or more.</p>
<p>There are an additional 50k reviews without any labels. These reviews are intended for unsupervised learning purposes (we’ll learn about unsupervised learning in the future). There is an equal number of reviews with a score of 4 or less and 5 or more.</p>
</section>
<section id="directory-structure" class="level3 page-columns page-full" data-number="1.2.3">
<h3 data-number="1.2.3" class="anchored" data-anchor-id="directory-structure"><span class="header-section-number">1.2.3</span> Directory structure</h3>
<div class="page-columns page-full"><p>The classification dataset file naming convention is <code>[DATASET]/[LABEL]/[ID]_[RATING].txt</code> where <code>DATASET</code> is one of <code>train</code> or <code>test</code>, <code>LABEL</code> is one of <code>pos</code> or <code>neg</code> (for positive and negative respectively), <code>ID</code> is a numeric identifier for a review, and <code>RATING</code> is the score the reviewer gave the movie.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">A word of warning for jupyter lab users. Jupyter crashed when I tried to open the directories containing the reviews (like <code>train/pos</code>). My guess is there’s too many files for jupyter to display and it becomes unresponsive. Your mileage may vary.</span></div></div>
<p>The unsupervised dataset file naming convention is <code>train/unsup/[ID]_0.txt</code> where <code>ID</code> is a numeric identifier for a review.</p>
<p>URLs to the reviews section are also provided in <code>[DATASET]/urls_[LABEL].txt</code>. The line <code>N</code> refers to <code>ID</code> <code>N</code> in the associated dataset/label combination. For example line 200 in <code>train/urls_pos.txt</code> refers to the reviews webpage for the movie of <code>train/pos/200_10.txt</code>. Here’s an example URL from one of these files: http://www.imdb.com/title/tt0064354/usercomments. It turns out IMDB has changed their URL format so this link is broken. They now use “reviews” in place of “usercomments” like http://www.imdb.com/title/tt0064354/reviews. It is possible to mine additional information about these movies using these URLs, but APIs change and trying to gather that information programmatically over the web could break in the future so this book will focus on just the reviews.</p>
</section>
</section>
<section id="question-the-dataset" class="level2 page-columns page-full" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="question-the-dataset"><span class="header-section-number">1.3</span> Question the dataset</h2>
<p>An integral part of building a machine learning model is understanding where the data comes from and how it was acquired. There may be assumptions made during the data curation process that you don’t agree with. An artefact in the data may have unintended side effects downstream, such as training a model that works very well on data it’s seen but performs poorly on data it hasn’t.</p>
<p>As you read about the dataset and it’s curation process, I recommend you keep asking “why?” to better understand the choices made during the curation process. Why did they use those specific thresholds for choosing positive vs negative labels? Why that ratio of positive/negative labels? Why that many reviews per movie? Why set up the train/test sets that way?</p>
<p>In parallel, also think about <em>how</em> you are going to leverage this data. Your end goal may be different from the curators of the dataset and that should be taken into account as you prepare the data for training machine learning models.</p>
<p>Here’s a couple questions that come to my mind.</p>
<ul>
<li>Why isn’t there a dataset for multi-label classification?</li>
<li>Why a maximum of 30 reviews per movie? Why not 10 or 50?</li>
<li>What was the rationale for picking the movies? Was it random or spread evenly by genre?</li>
<li>Were the movies made during a certain time period?</li>
</ul>
<div class="page-columns page-full"><p>Some of these questions we could answer ourselves if we want to and they can lead to a richer set of information. <a href="https://developer.imdb.com/">IMDB provides an API</a> to programmatically gather movie data over the web. With that tool one can gather movie genres, release dates, associated actors, and more. If we never ask the questions we’ll never think to look. Maybe we curate our own dataset because this one doesn’t provide what we need or it leads to further analysis of the data and the dataset is tweaked based on that analysis.</p><div class="no-row-height column-margin column-container"><span class="margin-aside"><a href="https://www.omdbapi.com/">OMDb API</a> is another API that provides IMDB metadata. I found their service to be much more transparent on pricing and easier to get access to.</span></div></div>
<section id="cleaning-the-data" class="level3 page-columns page-full" data-number="1.3.1">
<h3 data-number="1.3.1" class="anchored" data-anchor-id="cleaning-the-data"><span class="header-section-number">1.3.1</span> Cleaning the data</h3>
<p>The data is spread out across multiple files, we just need to gather it together in a nice package. That nice package will be a <a href="https://pandas.pydata.org/"><code>pandas</code></a> dataframe. Dataframes are tables. <code>pandas</code> provides a ton of functionality to manipulate tables and learn about their content. You can think of them as the python version of an excel spreadsheet. The boundaries between cleaning data and analysing data can be fuzzy at times, but for sake of simplicity we will only analyze the data as needed to properly clean it.</p>
<p>The pieces of information provided in this dataset are:</p>
<ul>
<li>ID</li>
<li>review</li>
<li>rating</li>
<li>label</li>
<li>movie ID (from the reviews URL <code>http://www.imdb.com/title/[MOVIE_ID]/usercomments</code>)</li>
</ul>
<p>Let’s gather the training set which is under <code>train/pos</code> and <code>train/neg</code>.</p>
<div id="610e64d2-1b25-4141-b42e-a15e6a20c0b4" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="kw">def</span> get_review_data(reviews_dir, urls_file):</span>
<span id="cb11-2"><a href="#cb11-2"></a>    <span class="co">"""Return a `pd.DataFrame` containing the review ID, title ID, rating, and review."""</span></span>
<span id="cb11-3"><a href="#cb11-3"></a>    <span class="cf">with</span> urls_file.<span class="bu">open</span>() <span class="im">as</span> f:</span>
<span id="cb11-4"><a href="#cb11-4"></a>        title_ids <span class="op">=</span> {i: url.split(<span class="st">'/'</span>)[<span class="dv">4</span>] <span class="cf">for</span> i, url <span class="kw">in</span> <span class="bu">enumerate</span>(f.readlines())}</span>
<span id="cb11-5"><a href="#cb11-5"></a></span>
<span id="cb11-6"><a href="#cb11-6"></a>    data <span class="op">=</span> []</span>
<span id="cb11-7"><a href="#cb11-7"></a>    <span class="cf">for</span> p <span class="kw">in</span> (reviews_dir).iterdir():</span>
<span id="cb11-8"><a href="#cb11-8"></a>        ID, rating <span class="op">=</span> <span class="bu">map</span>(<span class="bu">int</span>, p.stem.split(<span class="st">'_'</span>))</span>
<span id="cb11-9"><a href="#cb11-9"></a>        data.append(</span>
<span id="cb11-10"><a href="#cb11-10"></a>            {</span>
<span id="cb11-11"><a href="#cb11-11"></a>                <span class="st">"id"</span>: ID,</span>
<span id="cb11-12"><a href="#cb11-12"></a>                <span class="st">"movie_id"</span>: title_ids[ID],</span>
<span id="cb11-13"><a href="#cb11-13"></a>                <span class="st">"rating"</span>: rating,</span>
<span id="cb11-14"><a href="#cb11-14"></a>                <span class="st">"review"</span>: p.<span class="bu">open</span>().read().strip()</span>
<span id="cb11-15"><a href="#cb11-15"></a>            }</span>
<span id="cb11-16"><a href="#cb11-16"></a>        )</span>
<span id="cb11-17"><a href="#cb11-17"></a></span>
<span id="cb11-18"><a href="#cb11-18"></a>    <span class="cf">return</span> pd.DataFrame(data)</span>
<span id="cb11-19"><a href="#cb11-19"></a></span>
<span id="cb11-20"><a href="#cb11-20"></a><span class="kw">def</span> get_train_data():</span>
<span id="cb11-21"><a href="#cb11-21"></a>    dfs <span class="op">=</span> []</span>
<span id="cb11-22"><a href="#cb11-22"></a>    <span class="cf">for</span> label, label_name <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">'neg'</span>, <span class="st">'pos'</span>]):</span>
<span id="cb11-23"><a href="#cb11-23"></a>        df <span class="op">=</span> get_review_data(data_path<span class="op">/</span><span class="st">'train'</span><span class="op">/</span>label_name, data_path<span class="op">/</span><span class="ss">f'train/urls_</span><span class="sc">{</span>label_name<span class="sc">}</span><span class="ss">.txt'</span>)</span>
<span id="cb11-24"><a href="#cb11-24"></a>        df[<span class="st">'label'</span>] <span class="op">=</span> label</span>
<span id="cb11-25"><a href="#cb11-25"></a>        dfs.append(df)</span>
<span id="cb11-26"><a href="#cb11-26"></a>    <span class="cf">return</span> pd.concat(dfs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="1d45a4fb-a930-47a3-bde2-af3d04570e2a" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1"></a>train_df <span class="op">=</span> get_train_data()</span>
<span id="cb12-2"><a href="#cb12-2"></a>train_df.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">movie_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">review</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>7275</td>
<td>tt0082799</td>
<td>1</td>
<td>"National Lampoon Goes to the Movies" (1981) i...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>1438</td>
<td>tt0397501</td>
<td>4</td>
<td>Well! What can one say? Firstly, this adaptati...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>9137</td>
<td>tt0364986</td>
<td>1</td>
<td>What can I say, this is a piece of brilliant f...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>173</td>
<td>tt0283974</td>
<td>3</td>
<td>A decent sequel, but does not pack the punch o...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>8290</td>
<td>tt0314630</td>
<td>2</td>
<td>Alan Rudolph is a so-so director, without that...</td>
<td>0</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>Those look like reviews! Now that we have data in hand to play with, what questions can we answer about it? Maybe we should verify the information provided by the curators of this dataset.</p>
<ul>
<li>Are there 25k reviews in the train set?</li>
<li>Are they evenly split between positive and negative?</li>
<li>Is the max number of reviews per movie 30?</li>
</ul>
<div class="page-columns page-full"><p>We can use <code>DataFrame.info()</code> to answer the first question. This method gives some general information about the dataframe, including the column names, number of non-null values in each column, column data types, and the number of rows.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Null values include <code>None</code> and NaNs. NaN, or Not a Number, representa a number that is undefined, such as the result of dividing by 0.</span></div></div>
<div id="e78adf46-195b-47fb-b4f1-1fb9597be2cc" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>train_df.info()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 25000 entries, 0 to 12499
Data columns (total 5 columns):
 #   Column    Non-Null Count  Dtype 
---  ------    --------------  ----- 
 0   id        25000 non-null  int64 
 1   movie_id  25000 non-null  object
 2   rating    25000 non-null  int64 
 3   review    25000 non-null  object
 4   label     25000 non-null  int64 
dtypes: int64(3), object(2)
memory usage: 1.1+ MB</code></pre>
</div>
</div>
<p>This dataframe contains 25k entries, and all of those entries have non-null reviews. So the train set does contain 25k reviews. But we know nothing about the quality of these reviews. Are there duplicates? Empty strings? Are some complete gibberish? It’s impossible to qualitatively check every data point, but checking some basic properties of the data can go a long way. I like to call these sanity checks. Let’s start with duplicates. There’s many ways to check this. We’ll use <code>DataFrame.describe</code>.</p>
<div id="691f0adc-d6e7-40eb-a3b1-0e795f338c62" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>train_df.describe(include<span class="op">=</span>[<span class="bu">object</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">movie_id</th>
<th data-quarto-table-cell-role="th">review</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">count</td>
<td>25000</td>
<td>25000</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">unique</td>
<td>3456</td>
<td>24904</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">top</td>
<td>tt0374240</td>
<td>This show comes up with interesting locations ...</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">freq</td>
<td>30</td>
<td>3</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>The <code>include=[object]</code> argument tells <code>describe</code> to look at columns with the <code>object</code> data type instead of numeric data types. Strings fall under the <code>object</code> type in <code>pandas</code>.</p>
<p>The <code>movie_id</code> column shows the most frequent movie ID shows up 30 times. So we know there’s at most 30 reviews for a given movie in this dataset.</p>
<p>The <code>review</code> column has a count of 25k, but 24,904 unique entries which means there’s 96 duplicate reviews. From a training perspective, it doesn’t make sense to have duplicate items in the train set, but before we drop the duplicate reviews, let’s take a peek at them to see if they belong to the same movie and have the same ratings and labels.</p>
<div id="164bd7dc-e555-4789-a59d-c878692ed3c7" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1"></a>is_duplicate <span class="op">=</span> train_df[<span class="st">'review'</span>].duplicated(keep<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb16-2"><a href="#cb16-2"></a>duplicate_reviews <span class="op">=</span> train_df[is_duplicate]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>If you’re not familiar with <code>pandas</code>, then it may look like there’s a lot going on in these statements. <code>train_df['review']</code> accesses the <code>review</code> column in the dataframe. So <code>train_df['review'].duplicated(keep=False)</code> returns a list of <code>True</code> and <code>False</code> values for each index in the column indicating if the review at that index is a duplicate. <code>keep=False</code> tells the <code>duplicated</code> method to mark every instance of a duplicate as <code>True</code>. Now there is a list of <code>True</code>/<code>False</code> values associated with each review. This is passed to the dataframe as <code>train_df[is_duplicate]</code> which returns a filtered version of the dataframe where each row has a corresponding <code>True</code> value in <code>is_duplicate</code>. This gives us a dataframe with just the duplicated reviews.</p>
<p>Now that we have the duplicated reviews, let’s dig into them a bit. Are they for the same movie? Do they have the same rating or label?</p>
<div id="518b1c1f-4359-4a23-9187-ab109d82bbf5" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>duplicate_nunique <span class="op">=</span> duplicate_reviews.groupby(<span class="st">'review'</span>).agg(<span class="st">'nunique'</span>).head()</span>
<span id="cb17-2"><a href="#cb17-2"></a>duplicate_nunique.head(<span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">movie_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">review</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">'Dead Letter Office' is a low-budget film about a couple of employees of the Australian postal service, struggling to rebuild their damaged lives. Unfortunately, the acting is poor and the links between the characters' past misfortunes and present mindsets are clumsily and over-schematically represented. What's most disappointing of all, however, is the portrayal is life in the office of the film's title: there's no mechanisation whatsoever, and it's quite impossible to ascertain what any of the staff really do for a living. Granted, part of the plot is that the office is threatened with closure, but this sort of office surely closed in the 1930s, if it ever truly existed. It's a shame, as the film's overall tone is poignant and wry, and there's some promise in the scenario: but few of the details convince. Overall, it feels the work of someone who hasn't actually experienced much of real life; a student film, with a concept and an outline, but sadly little else.</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">.......Playing Kaddiddlehopper, Col San Fernando, etc. the man was pretty wide ranging and a scream. I love watching him interact w/ Amanda Blake, or Don Knotts or whomever--he clearly was having a ball and I think he made it easier on his guests as well--so long as they Knew ahead of time it wasn't a disciplined, 19 take kind of production. Relax and be loose was clearly the name of the game there.&lt;br /&gt;&lt;br /&gt;He reminds me of guys like Milton Berle, Benny Hill, maybe Jerry Lewis some too. Great timing, ancient gags that kept audiences in stitches for decades, sheer enjoyment about what he was doing. His sad little clown he played was good too--but in a touching manner.&lt;br /&gt;&lt;br /&gt;Personally I think he's great, having just bought a two DVD set of his shows from '61 or so, it brings his stuff back in a fond way for me. I can remember seeing him on TV at the end of his run when he was winding up the series in 1971 or so.&lt;br /&gt;&lt;br /&gt;Check this out if you are a fan or curious. He was a riot.</td>
<td>2</td>
<td>2</td>
<td>1</td>
<td>1</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">&lt;br /&gt;&lt;br /&gt;Back in his youth, the old man had wanted to marry his first cousin, but his family forbid it. Many decades later, the old man has raised three children (two boys and one girl), and allows his son and daughter to marry and have children. Soon, the sister is bored with brother #1, and jumps in the bed of brother #2.&lt;br /&gt;&lt;br /&gt;One might think that the three siblings are stuck somewhere on a remote island. But no -- they are upper class Europeans going to college and busy in the social world.&lt;br /&gt;&lt;br /&gt;Never do we see a flirtatious moment between any non-related female and the two brothers. Never do we see any flirtatious moment between any non-related male and the one sister. All flirtatious moments are shared between only between the brothers and sister.&lt;br /&gt;&lt;br /&gt;The weakest part of GLADIATOR was the incest thing. The young emperor Commodus would have hundreds of slave girls and a city full of marriage-minded girls all over him, but no -- he only wanted his sister? If movie incest is your cup of tea, then SUNSHINE will (slowly) thrill you to no end.</td>
<td>2</td>
<td>1</td>
<td>1</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p><code>groupby</code> is grouping rows with the same <code>review</code> column together into their own dataframes. The return value of this operation is a <code>DataFrameGroupBy</code>. This special dataframe type performs operations on each group as if they were their own dataframe instead of all rows in the dataframe. <code>agg</code> performs an operation on the entire dataframe, but since this is a <code>DataFrameGroupBy</code> object, the <code>agg</code> method is applied to each group. In this case it counts the number of unique values in each column.</p>
<p>It turns out there are duplicate reviews for different movie IDs. It’s possible duplicate reviews with different ratings or labels but since we only looked at the first three rows we can’t say if that’s true or not. Let’s inspect the two reviews above that have multiple movie IDs.</p>
<div id="cb7587f1-fedc-4d0f-8567-92f185d8abba" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a>is_first2 <span class="op">=</span> duplicate_reviews[<span class="st">'review'</span>].isin(duplicate_nunique.index[:<span class="dv">2</span>])</span>
<span id="cb18-2"><a href="#cb18-2"></a>duplicate_reviews[is_first2]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">movie_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">review</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">10893</td>
<td>985</td>
<td>tt0223119</td>
<td>4</td>
<td>'Dead Letter Office' is a low-budget film abou...</td>
<td>0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">12445</td>
<td>4102</td>
<td>tt0118939</td>
<td>4</td>
<td>'Dead Letter Office' is a low-budget film abou...</td>
<td>0</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">101</td>
<td>6069</td>
<td>tt0163806</td>
<td>8</td>
<td>.......Playing Kaddiddlehopper, Col San Fernan...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">5458</td>
<td>9319</td>
<td>tt0043224</td>
<td>8</td>
<td>.......Playing Kaddiddlehopper, Col San Fernan...</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="page-columns page-full"><p>Remember we are provided a URL for the comments section of each review which is where we extract the movie ID from. This means we can go backwards from movie ID to movie URL. One review is for movies at the URLs <a href="http://www.imdb.com/title/tt0223119/reviews">http://www.imdb.com/title/tt0223119/reviews</a> and <a href="http://www.imdb.com/title/tt0118939/reviews">http://www.imdb.com/title/tt0118939/reviews</a> and the other at <a href="http://www.imdb.com/title/tt0163806/review">http://www.imdb.com/title/tt0163806/reviews</a> and <a href="http://www.imdb.com/title/tt0043224/reviews">http://www.imdb.com/title/tt0043224/reviews</a>. When I click on each pair one gets redirected to the other. Movie IDs tt0223119 and tt0118939 are for <a href="https://www.imdb.com/title/tt0118939/"><em>Dead Letter Office</em></a>, and tt0163806 and tt0043224 are for <a href="https://www.imdb.com/title/tt0043224/"><em>The Red Skelton Hour</em></a>. Although they have different movie IDs, they are reviews for the <em>same movie</em> and therefore are truly duplicate reviews. This is a one-to-many relationship; one movie can have many IDs.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">I checked these links in August 2024. The URL endpoints may have changed in the future.</span></div></div>
<p>While it’s not incredibly important, <em>The Red Skelton Hour</em> is actually a TV show. It turns out this dataset contains reviews for movies <em>and tv shows</em>. See what a little digging can turn up?</p>
<p>We could check every single movie ID for duplicate reviews manually (or have an intern do it) because it’s possible there are duplicate reviews for different movies, but our task is to predict a label (positive or negative) given a review. Our models don’t need to see the same review over and over again in order to make predictions about them…unless duplicate reviews have different labels! Why would we want to train on both examples in this case? If the same review can be positive or negative, then training a machine learning model with both examples will teach the model to be uncertain about some reviews where the language is more ambiguous.</p>
<p>Let’s see if there’s any duplicate reviews with multiple labels or ratings.</p>
<div id="00642bc3-94b5-4ff6-bc24-1cdadd245e3d" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1"></a>different_labels <span class="op">=</span> (duplicate_nunique[<span class="st">'label'</span>] <span class="op">&gt;</span> <span class="dv">1</span>) <span class="op">|</span> (duplicate_nunique[<span class="st">'rating'</span>] <span class="op">&gt;</span> <span class="dv">1</span>)</span>
<span id="cb19-2"><a href="#cb19-2"></a>duplicate_nunique[different_labels]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">movie_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th">review</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
</tbody>
</table>

</div>
</div>
</div>
<p>There isn’t, which means these reviews stem from duplicate movie IDs. Since the labels are the same for each duplicate, I feel confident in just removing the duplicate entries. I’ve taken the liberty of performing this analysis on the test set and found the same issue, so we’ll remove duplicates from the test set as well.</p>
<div id="67daecd1-32b2-4d6d-92bf-d798cf7dfa19" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="kw">def</span> get_df(dataset):</span>
<span id="cb20-2"><a href="#cb20-2"></a>    dfs <span class="op">=</span> []</span>
<span id="cb20-3"><a href="#cb20-3"></a>    <span class="cf">for</span> label, label_name <span class="kw">in</span> <span class="bu">enumerate</span>([<span class="st">'neg'</span>, <span class="st">'pos'</span>]):</span>
<span id="cb20-4"><a href="#cb20-4"></a>        df <span class="op">=</span> get_review_data(data_path<span class="op">/</span>dataset<span class="op">/</span>label_name, data_path<span class="op">/</span>dataset<span class="op">/</span><span class="ss">f'urls_</span><span class="sc">{</span>label_name<span class="sc">}</span><span class="ss">.txt'</span>)</span>
<span id="cb20-5"><a href="#cb20-5"></a>        df[<span class="st">'label'</span>] <span class="op">=</span> label</span>
<span id="cb20-6"><a href="#cb20-6"></a>        dfs.append(df)</span>
<span id="cb20-7"><a href="#cb20-7"></a>    <span class="cf">return</span> pd.concat(dfs)</span>
<span id="cb20-8"><a href="#cb20-8"></a></span>
<span id="cb20-9"><a href="#cb20-9"></a><span class="kw">def</span> get_train_data(dedup<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb20-10"><a href="#cb20-10"></a>    rv <span class="op">=</span> get_df(<span class="st">"train"</span>)</span>
<span id="cb20-11"><a href="#cb20-11"></a>    <span class="cf">if</span> dedup:</span>
<span id="cb20-12"><a href="#cb20-12"></a>        <span class="cf">return</span> rv.drop_duplicates(<span class="st">"review"</span>).copy()</span>
<span id="cb20-13"><a href="#cb20-13"></a>    <span class="cf">return</span> rv</span>
<span id="cb20-14"><a href="#cb20-14"></a></span>
<span id="cb20-15"><a href="#cb20-15"></a><span class="kw">def</span> get_test_data(dedup<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb20-16"><a href="#cb20-16"></a>    rv <span class="op">=</span> get_df(<span class="st">"test"</span>)</span>
<span id="cb20-17"><a href="#cb20-17"></a>    <span class="cf">if</span> dedup:</span>
<span id="cb20-18"><a href="#cb20-18"></a>        <span class="cf">return</span> rv.drop_duplicates(<span class="st">"review"</span>).copy()</span>
<span id="cb20-19"><a href="#cb20-19"></a>    <span class="cf">return</span> rv</span>
<span id="cb20-20"><a href="#cb20-20"></a></span>
<span id="cb20-21"><a href="#cb20-21"></a>train_df <span class="op">=</span> get_train_data()</span>
<span id="cb20-22"><a href="#cb20-22"></a>train_df.groupby(<span class="st">'label'</span>).describe(include<span class="op">=</span><span class="st">'object'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th colspan="4" data-quarto-table-cell-role="th" data-halign="left">movie_id</th>
<th colspan="4" data-quarto-table-cell-role="th" data-halign="left">review</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">unique</th>
<th data-quarto-table-cell-role="th">top</th>
<th data-quarto-table-cell-role="th">freq</th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">unique</th>
<th data-quarto-table-cell-role="th">top</th>
<th data-quarto-table-cell-role="th">freq</th>
</tr>
<tr class="header">
<th data-quarto-table-cell-role="th">label</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>12432</td>
<td>2950</td>
<td>tt0888019</td>
<td>30</td>
<td>12432</td>
<td>12432</td>
<td>Well, what can it be said about this disaster?...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>12472</td>
<td>1390</td>
<td>tt0086383</td>
<td>30</td>
<td>12472</td>
<td>12472</td>
<td>After the usual chase scene, Jerry accidentall...</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="080f527c-8cd1-49ce-b76a-f58770f00134" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1"></a>train_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(24904, 5)</code></pre>
</div>
</div>
<p>We don’t quite have 25k reviews split evenly across labels, but it’s close enough. I think this is in good shape and we can turn our attention to the test set.</p>
<div id="c1e8b58d-0118-4dbb-8daa-dcf45b8b3dc3" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1"></a>test_df <span class="op">=</span> get_test_data()</span>
<span id="cb23-2"><a href="#cb23-2"></a>test_df.groupby(<span class="st">'label'</span>).describe(include<span class="op">=</span><span class="st">'object'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th colspan="4" data-quarto-table-cell-role="th" data-halign="left">movie_id</th>
<th colspan="4" data-quarto-table-cell-role="th" data-halign="left">review</th>
</tr>
<tr class="odd">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">unique</th>
<th data-quarto-table-cell-role="th">top</th>
<th data-quarto-table-cell-role="th">freq</th>
<th data-quarto-table-cell-role="th">count</th>
<th data-quarto-table-cell-role="th">unique</th>
<th data-quarto-table-cell-role="th">top</th>
<th data-quarto-table-cell-role="th">freq</th>
</tr>
<tr class="header">
<th data-quarto-table-cell-role="th">label</th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>12361</td>
<td>3005</td>
<td>tt0093142</td>
<td>30</td>
<td>12361</td>
<td>12361</td>
<td>I'm glad that I did not expect too much when I...</td>
<td>1</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>12440</td>
<td>1351</td>
<td>tt0312004</td>
<td>30</td>
<td>12440</td>
<td>12440</td>
<td>Once upon a time, Troma, the company that brou...</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="8ae6b1ff-6949-4887-a9c6-bf5e2aa8017a" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>test_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>(24801, 5)</code></pre>
</div>
</div>
<p>We’ve removed about 200 reviews from the test set and can start digging in to comparing the test set to the train set.</p>
</section>
<section id="train-test-contamination" class="level3 page-columns page-full" data-number="1.3.2">
<h3 data-number="1.3.2" class="anchored" data-anchor-id="train-test-contamination"><span class="header-section-number">1.3.2</span> Train-test contamination</h3>
<p>Now let’s talk a bit about what the test set is used for. It’s a separate set of data used to evaluate a machine learning model after it’s trained. It is data used to measure the performance of a model on data it’s never seen before. This is important because when a model is used in production, it will be making predictions about all kinds of inputs it wasn’t trained on and it needs to generalize well beyond the training data. <strong>We do not want data leaking from the train set into the test set.</strong></p>
<p>Easy enough to check.</p>
<div id="df95771d-d6db-49a1-8d64-265eebc02cd3" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1"></a>leak_df <span class="op">=</span> test_df[test_df[<span class="st">'review'</span>].isin(train_df[<span class="st">'review'</span>])]</span>
<span id="cb26-2"><a href="#cb26-2"></a>leak_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>(123, 5)</code></pre>
</div>
</div>
<p>There’s 123 reviews from the train set in the test set.</p>
<p>Let’s think about that for a second. The reviews in the test set should be for movies that aren’t reviewed in the train set, but we have 123 reviews in the test set that are duplicates of those in the train set. How could this happen?</p>
<p>Remember that we saw duplicate reviews in the train set. This was a result of the same movie having multiple movie IDs. That could explain what’s happening here. Maybe the reviews in both the train and test sets have different movie IDs. We can test that!</p>
<div id="73976542-c5f1-4242-a0bd-b94c1605929f" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1"></a>both_df <span class="op">=</span> train_df.merge(test_df, on<span class="op">=</span><span class="st">'review'</span>)</span>
<span id="cb28-2"><a href="#cb28-2"></a>(both_df[<span class="st">'movie_id_x'</span>] <span class="op">==</span> both_df[<span class="st">'movie_id_y'</span>]).<span class="bu">any</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>np.False_</code></pre>
</div>
</div>
<p>Bingo, by aligning the reviews with <code>merge()</code> we can directly compare movie IDs for duplicate reviews and none of them are the same. When this dataset was curated, this one-to-many relationship in the IMDB wasn’t accounted for and resulted in not just duplicate reviews in the train and test sets independently, but also leakage of data from the train set into the test set. It gets worse though, we could remove the training reviews that leaked into the test set, but the test set <em>should only contain reviews for movies that aren’t reviewed in the train set</em>. Because of the one-to-many relationship of movie title and movie IDs we have to further process the dataset to see if the movies reviewed in the test set are all different from those in the train set, even after removing duplicates.</p>
<p>Why is it important that there are no overlapping movies when the reviews are different? The curators of this dataset give a good explanation in the README they provide,</p>
<blockquote class="blockquote">
<p>“In the entire collection, no more than 30 reviews are allowed for any given movie because reviews for the same movie tend to have correlated ratings. Further, the train and test sets contain a disjoint set of movies, so no significant performance is obtained by memorizing movie-unique terms and their associated with observed labels.” <span class="citation" data-cites="maas-EtAl:2011:ACL-HLT2011">(<a href="../references.html#ref-maas-EtAl:2011:ACL-HLT2011" role="doc-biblioref">Maas et al. 2011</a>)</span></p>
</blockquote>
<p>Our goal is to train machine learning models that recognize general patterns of language to predict positive or negative sentiment for a given piece of text. If all the reviews in the train set for <em>Batman Begins</em> are positive, the model may learn to associate words like “Batman”, “Bruce Wayne”, “Christian Bale”, and “Christopher Nolan” with positive sentiment. This doesn’t generalize to other movies. If reviews for <em>Batman Begins</em> are in the test set, the model will likely correctly predict those reviews improving it’s performance on the test set. The test set is supposed to be unbiased, but that goes out the window when data from the train set leaks into the test set.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are a few forms of data leakage, but what I’ve described here is often called “train-test contamination”. Basically when there’s information specific to the train set that also shows up in the test set. In our case it’s duplicate reviews and movie specific terms. It’s a real problem in machine learning. It can make AI look better than it really is. Finding it in datasets can be tricky, especially as datasets get bigger and bigger. Thought needs to go into preventing sources of leakage and you may never catch every instance of leakage. For example, there’s another instance of leakage that wasn’t considered for this dataset. The train and test sets should contain reviews for a disjoint set of <em>reviewers</em> because individual reviewers may use specific terms or have unique speech patterns that do not generalize to all reviewers and a machine learning model could learn that.</p>
</div>
</div>
<p>First we’ll remove the leakage of reviews from the train set into the test set.</p>
<div id="8c6ab8ca-08da-4a89-876c-e2aa4ba6f7d2" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1"></a><span class="kw">def</span> get_train_test_data():</span>
<span id="cb30-2"><a href="#cb30-2"></a>    train_df <span class="op">=</span> get_train_data()</span>
<span id="cb30-3"><a href="#cb30-3"></a>    test_df <span class="op">=</span> get_test_data()</span>
<span id="cb30-4"><a href="#cb30-4"></a>    test_df <span class="op">=</span> test_df[<span class="op">~</span>test_df[<span class="st">'review'</span>].isin(train_df[<span class="st">'review'</span>])].copy()</span>
<span id="cb30-5"><a href="#cb30-5"></a>    <span class="cf">return</span> train_df, test_df</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Now, let’s handle the leakage of movies from the train set into the test set. The way movie IDs work in IMDB is there’s one main ID for a movie and other movie IDs for that movie point to the main ID. We saw this earlier when we looked at URLs for duplicate reviews. When you visit those URLs, the duplicate movie ID redirects to the main one. Try it with these URLS, <a href="http://www.imdb.com/title/tt0223119/reviews">http://www.imdb.com/title/tt0223119/reviews</a> and <a href="http://www.imdb.com/title/tt0118939/reviews">http://www.imdb.com/title/tt0118939/reviews</a>. Notice how the first link redirects to the second link. That’s because <code>tt0118939</code> is the main ID for that movie and <code>tt0223119</code> is a duplicate ID that points to it.</p>
<div class="page-columns page-full"><p>I’ve taken the liberty of creating a csv file that maps every movie ID in this dataset to their corresponding main movie ID.. We’ll use this to replace the movie IDs in our train and test sets then check how many reviews there are per movie and if there’s any overlap of movies between the train and test sets.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">If you’d like to see details on how I did this check out this <a href="https://github.com/spenceforce/NLP-Simple-to-Spectacular/blob/main/01_data/README.md">README</a>.</span></div></div>
<div id="0600c0bb-234d-4ec0-bb0f-c52f33ed01de" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1"></a><span class="kw">def</span> get_review_data(reviews_dir, urls_file):</span>
<span id="cb31-2"><a href="#cb31-2"></a>    <span class="co">"""Return a `pd.DataFrame` containing the review ID, title ID, rating, and review."""</span></span>
<span id="cb31-3"><a href="#cb31-3"></a>    <span class="cf">with</span> urls_file.<span class="bu">open</span>() <span class="im">as</span> f:</span>
<span id="cb31-4"><a href="#cb31-4"></a>        movie_ids <span class="op">=</span> {i: url.split(<span class="st">'/'</span>)[<span class="dv">4</span>] <span class="cf">for</span> i, url <span class="kw">in</span> <span class="bu">enumerate</span>(f.readlines())}</span>
<span id="cb31-5"><a href="#cb31-5"></a></span>
<span id="cb31-6"><a href="#cb31-6"></a>    movie_id_map <span class="op">=</span> <span class="bu">dict</span>(pd.read_csv(<span class="st">'all_movie_ids.csv'</span>).values)</span>
<span id="cb31-7"><a href="#cb31-7"></a></span>
<span id="cb31-8"><a href="#cb31-8"></a>    data <span class="op">=</span> []</span>
<span id="cb31-9"><a href="#cb31-9"></a>    <span class="cf">for</span> p <span class="kw">in</span> (reviews_dir).iterdir():</span>
<span id="cb31-10"><a href="#cb31-10"></a>        ID, rating <span class="op">=</span> <span class="bu">map</span>(<span class="bu">int</span>, p.stem.split(<span class="st">'_'</span>))</span>
<span id="cb31-11"><a href="#cb31-11"></a>        data.append(</span>
<span id="cb31-12"><a href="#cb31-12"></a>            {</span>
<span id="cb31-13"><a href="#cb31-13"></a>                <span class="st">"id"</span>: ID,</span>
<span id="cb31-14"><a href="#cb31-14"></a>                <span class="st">"movie_id"</span>: movie_id_map[movie_ids[ID]],</span>
<span id="cb31-15"><a href="#cb31-15"></a>                <span class="st">"rating"</span>: rating,</span>
<span id="cb31-16"><a href="#cb31-16"></a>                <span class="st">"review"</span>: p.<span class="bu">open</span>().read().strip()</span>
<span id="cb31-17"><a href="#cb31-17"></a>            }</span>
<span id="cb31-18"><a href="#cb31-18"></a>        )</span>
<span id="cb31-19"><a href="#cb31-19"></a></span>
<span id="cb31-20"><a href="#cb31-20"></a>    <span class="cf">return</span> pd.DataFrame(data)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Are there any movies in the original train set with more than 30 reviews?</p>
<div id="3d0b3952-26f5-4076-b4b0-75713ba14ca0" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1"></a>get_train_data(dedup<span class="op">=</span><span class="va">False</span>).groupby(<span class="st">'movie_id'</span>).size().value_counts().sort_index(ascending<span class="op">=</span><span class="va">False</span>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>32      2
30    232
29      9
28      5
27     14
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>Yes there is. And what about in the deduplicated train set?</p>
<div id="ea767139-f20f-4476-a5ed-5984025ffd40" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1"></a>get_train_data(dedup<span class="op">=</span><span class="va">True</span>).groupby(<span class="st">'movie_id'</span>).size().value_counts().sort_index(ascending<span class="op">=</span><span class="va">False</span>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>30    222
29     19
28      5
27     14
26     11
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>No there isn’t. So deduplication actually brings the maximum number of reviews per movie down to 30 which was the original intent of this dataset. Let’s repeat this for the test set.</p>
<div id="da313898-ded5-4b2d-989b-bba79a4d849a" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1"></a>get_test_data(dedup<span class="op">=</span><span class="va">False</span>).groupby(<span class="st">'movie_id'</span>).size().value_counts().sort_index(ascending<span class="op">=</span><span class="va">False</span>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>60    1
48    1
41    1
40    1
33    1
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>By comparison that’s pretty dramatic. We see one movie with 60 reviews and a couple with over 40!</p>
<div id="844e3b1f-36dd-4db9-8371-59055584e2f0" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1"></a>get_test_data(dedup<span class="op">=</span><span class="va">True</span>).groupby(<span class="st">'movie_id'</span>).size().value_counts().sort_index(ascending<span class="op">=</span><span class="va">False</span>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>30    197
29     16
28     10
27     11
26     11
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>But it’s the same story when we deduplicate the reviews. It seems the movies with more than 30 reviews are due to duplicate reviews caused by movies with multiple movie IDs. This is good news because the deduplication takes care of the overrepresented movies for us.</p>
<p>This leaves one more question about train test contamination though. Are there any movies with reviews in the train and test set?</p>
<div id="2284f28c-7325-47ce-b599-fca2c2ce098e" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1"></a>train_df, test_df <span class="op">=</span> get_train_test_data()</span>
<span id="cb40-2"><a href="#cb40-2"></a>test_df[<span class="st">'movie_id'</span>].isin(train_df[<span class="st">'movie_id'</span>]).<span class="bu">any</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>np.True_</code></pre>
</div>
</div>
<p>That is unfortunate. After removing reviews from the test set that appear in the train set, we’re still left with reviews in the test set for at least one movie that is reviewed in the train set. Let’s dig in a little.</p>
<div id="c4b939e6-e9d9-4042-8f01-96a39848f045" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1"></a>overlapping_movies <span class="op">=</span> test_df[test_df[<span class="st">'movie_id'</span>].isin(train_df[<span class="st">'movie_id'</span>])]</span>
<span id="cb42-2"><a href="#cb42-2"></a>overlapping_movies.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>(103, 5)</code></pre>
</div>
</div>
<p>There’s 103 reviews in the test set that shouldn’t be there because their associated movie is reviewed in the train set. How many movies are we talking?</p>
<div id="2d0b5763-7d89-446a-af32-0bdbcee256e1" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1"></a><span class="bu">len</span>(overlapping_movies[<span class="st">'movie_id'</span>].unique())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>7</code></pre>
</div>
</div>
<p>103 reviews across 7 movies. Let’s also remove these from the test set as they can artificially inflate the benchmarking performance of our models.</p>
<div id="a3a1e620-4d90-4106-9db9-8cd994febdf2" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1"></a><span class="kw">def</span> get_train_test_data():</span>
<span id="cb46-2"><a href="#cb46-2"></a>    train_df <span class="op">=</span> get_train_data()</span>
<span id="cb46-3"><a href="#cb46-3"></a>    test_df <span class="op">=</span> get_test_data()</span>
<span id="cb46-4"><a href="#cb46-4"></a>    test_df <span class="op">=</span> test_df[(<span class="op">~</span>test_df[<span class="st">'movie_id'</span>].isin(train_df[<span class="st">'movie_id'</span>]))].copy()</span>
<span id="cb46-5"><a href="#cb46-5"></a>    <span class="cf">return</span> train_df, test_df</span>
<span id="cb46-6"><a href="#cb46-6"></a></span>
<span id="cb46-7"><a href="#cb46-7"></a>train_df, test_df <span class="op">=</span> get_train_test_data()</span>
<span id="cb46-8"><a href="#cb46-8"></a>train_df.shape, test_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>((24904, 5), (24576, 5))</code></pre>
</div>
</div>
<p>We now have 24,904 reviews in the train set and 24,576 in the test set. By removing all reviews from the test set with a movie ID seen in the train set, that should handle duplicate reviews across these groups as well as duplicate movies, but there’s still something wrong with our test set. Our original test set was 25k. We removed 199 duplicate reviews in the test set, then 123 reviews seen in the train set, then 103 reviews with movie IDs seen in the train set. Adding that up doesn’t give us 24,576…</p>
<div id="53b36727-f795-4b4f-b9e7-96e3cb0ed807" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1"></a><span class="dv">25000</span> <span class="op">-</span> <span class="dv">199</span> <span class="op">-</span> <span class="dv">123</span> <span class="op">-</span> <span class="dv">103</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>24575</code></pre>
</div>
</div>
<p>Our test set has one to many reviews. That’s because we didn’t actually remove all of the reviews in the test set seen in the train set, we just removed the reviews with the same movie IDs. There’s one review in the train and test sets, it’s just for <strong><em>different movies</em></strong>!</p>
<div id="04869f65-e1c7-4205-a534-4a544d80e3ff" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1"></a>test_df[test_df[<span class="st">'review'</span>].isin(train_df[<span class="st">'review'</span>])]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">movie_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">review</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">10020</td>
<td>12159</td>
<td>tt0182766</td>
<td>8</td>
<td>There has been a political documentary, of rec...</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div id="61dd8597-6a1c-4f5d-9c8a-123df2d0815d" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1"></a>train_df[train_df[<span class="st">'review'</span>].isin(test_df[<span class="st">'review'</span>])]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<div>


<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">id</th>
<th data-quarto-table-cell-role="th">movie_id</th>
<th data-quarto-table-cell-role="th">rating</th>
<th data-quarto-table-cell-role="th">review</th>
<th data-quarto-table-cell-role="th">label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">355</td>
<td>10643</td>
<td>tt0184773</td>
<td>8</td>
<td>There has been a political documentary, of rec...</td>
<td>1</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<p>It turns out these two movies are part of a documentary series and somebody wrote the same review for both documentaries. One documentary ended up in the train set, the other in the test set, and one reviewer happened to write the same review for both. All that’s left is for us to remove the reviews from the test set seen in the train set <em>and</em> the reviews from the test set with movie IDs in the train set.</p>
<div id="934cbd28-9322-40fe-b20a-008f45771dfa" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1"></a><span class="kw">def</span> get_train_test_data():</span>
<span id="cb52-2"><a href="#cb52-2"></a>    train_df <span class="op">=</span> get_train_data()</span>
<span id="cb52-3"><a href="#cb52-3"></a>    test_df <span class="op">=</span> get_test_data()</span>
<span id="cb52-4"><a href="#cb52-4"></a>    same_review <span class="op">=</span> test_df[<span class="st">'review'</span>].isin(train_df[<span class="st">'review'</span>])</span>
<span id="cb52-5"><a href="#cb52-5"></a>    same_movie <span class="op">=</span> test_df[<span class="st">'movie_id'</span>].isin(train_df[<span class="st">'movie_id'</span>])</span>
<span id="cb52-6"><a href="#cb52-6"></a>    test_df <span class="op">=</span> test_df[<span class="op">~</span>same_review <span class="op">&amp;</span> <span class="op">~</span>same_movie].copy()</span>
<span id="cb52-7"><a href="#cb52-7"></a>    <span class="cf">return</span> train_df, test_df</span>
<span id="cb52-8"><a href="#cb52-8"></a></span>
<span id="cb52-9"><a href="#cb52-9"></a>train_df, test_df <span class="op">=</span> get_train_test_data()</span>
<span id="cb52-10"><a href="#cb52-10"></a>train_df.shape, test_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>((24904, 5), (24575, 5))</code></pre>
</div>
</div>
</section>
</section>
<section id="reflection" class="level2 page-columns page-full" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="reflection"><span class="header-section-number">1.4</span> Reflection</h2>
<p>With that, our data cleaning journey comes to an end. Yes, there is more that could be done, like ensuring no reviews from the same reviewer show up in the train and test sets, but we don’t have user IDs associated with these reviews. Besides, the process would look similar to what we’ve already done, just with a little more leg work. We covered a lot of ground, and while we’re here I’d like to take a moment to reflect on what we found.</p>
<ul>
<li>Duplicate reviews in both the train and test sets.</li>
<li>More than 30 reviews for some movies.
<ul>
<li>Fortunately these were all duplicate reviews.</li>
</ul></li>
<li>Train-test contamination.</li>
</ul>
<div class="page-columns page-full"><p>I especially want to draw your attention to the train-test contamination. The amount of contamination in this dataset may be negligible when it comes to benchmarking machine learning models, I don’t really know. But the fact that it’s there and that this dataset is provided by <a href="https://pytorch.org/text/stable/datasets.html#imdb">multiple</a> <a href="https://www.tensorflow.org/datasets/catalog/imdb_reviews">deep learning</a> <a href="https://docs.fast.ai/data.external.html#main-datasets">libraries</a> as well as used for <a href="https://arxiv.org/abs/1801.06146">benchmarking tasks in research</a> <span class="citation" data-cites="DBLP:journals/corr/abs-1801-06146">(<a href="../references.html#ref-DBLP:journals/corr/abs-1801-06146" role="doc-biblioref">Howard and Ruder 2018</a>)</span> should make you pause . I’ve used datasets at face value without questioning them and I guarantee people have taken this dataset at face value. These libraries provide the data as-is. 25k train and 25k test reviews, but we know there’s not really 25k reviews in each set. This is not a critique of the dataset or it’s curators, the libraries that provide it, or the researchers that use it. This is a reminder to verify the data is actually what you think it is because we’ve seen here that it isn’t always what it looks like.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Researchers may perform their own preprocessing of the data as we have here. I point to this paper as an example of researchers using the dataset because it is a popular dataset, not as an example of someone using it without preprocessing. In a later chapter, we will reimplement the method in this paper because I think it’s that important.</span></div></div>
<section id="keep-asking-why" class="level3" data-number="1.4.1">
<h3 data-number="1.4.1" class="anchored" data-anchor-id="keep-asking-why"><span class="header-section-number">1.4.1</span> Keep asking “why?”</h3>
<p>Now that we’ve reached the end, did we answer all the questions we set out to answer? Did you come up with other questions while we worked through this? If we created a similar dataset from scratch today, what would you do differently?</p>
</section>
</section>
<section id="unsupervised-learning-data" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="unsupervised-learning-data"><span class="header-section-number">1.5</span> Unsupervised learning data</h2>
<p>But wait there’s more. We’ll also be covering unsupervised learning topics in this book. The train/test sets have labels, 0 or 1, which allows them to be used in a <em>supervised</em> learning fashion. In supervised learning we have real outputs, the review labels in this case, to compare to our machine learning model outputs. We can supervise the models learning by comparing it’s outputs to the labels and let the model know how it’s doing. Unsupervised learning is just input data. There’s no label to use as a comparator.</p>
<p>The IMDB dataset includes an unsupervised learning dataset. The unsupervised set has no ratings and no labels. It’s just reviews. Like the train and test set we’ve already gone over, the same principle of deduplication applies and that’s really all we need.</p>
<div id="f33fce42-e663-458a-8a73-02f8c67dee98" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1"></a><span class="kw">def</span> get_unsup_data(dedup<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb54-2"><a href="#cb54-2"></a>    rv <span class="op">=</span> get_review_data(data_path<span class="op">/</span><span class="st">"train/unsup"</span>, data_path<span class="op">/</span><span class="st">"train/urls_unsup.txt"</span>)</span>
<span id="cb54-3"><a href="#cb54-3"></a>    rv.drop(columns<span class="op">=</span><span class="st">"rating"</span>, inplace<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb54-4"><a href="#cb54-4"></a>    <span class="co"># Drop the ratings column since every review in the unsupervised set is</span></span>
<span id="cb54-5"><a href="#cb54-5"></a>    <span class="co"># given a rating of 0 regardless of what it's rating is.</span></span>
<span id="cb54-6"><a href="#cb54-6"></a>    <span class="cf">if</span> dedup:</span>
<span id="cb54-7"><a href="#cb54-7"></a>        <span class="cf">return</span> rv.drop_duplicates(<span class="st">"review"</span>).copy()</span>
<span id="cb54-8"><a href="#cb54-8"></a>    <span class="cf">return</span> rv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="eda9fcdb-0418-40bf-91ce-01714f621d62" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1"></a>unsup_df <span class="op">=</span> get_unsup_data()</span>
<span id="cb55-2"><a href="#cb55-2"></a>unsup_df.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>(49507, 3)</code></pre>
</div>
</div>
<div id="cf9a465d-ed72-43af-b577-55b61d6c8545" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1"></a>unsup_df.groupby(<span class="st">'movie_id'</span>).size().value_counts().sort_index(ascending<span class="op">=</span><span class="va">False</span>).head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="65">
<pre><code>30    396
29     23
28     18
27     25
26     23
Name: count, dtype: int64</code></pre>
</div>
</div>
<p>Ok, we’re really done now. Thanks for bearing with me. Cleaning data is probably my least favorite part of machine learning because it can feel like busy work, but it’s so important. Even if you leave the dataset the way you found it, it’s a great opportunity to learn about the dataset before you do any modeling. I often find that data cleaning is an ongoing process as I build machine learning models because the models can point to oddities in the data I never saw during my initial exploration. You will find article after article about how machine learning works, with little discussion of how the data was prepared. I want you to walk away from this chapter knowing that cleaning data, analysis, and machine learning are all intertwined.</p>
<p>In the next chapter we’ll build our first model from scratch.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-DBLP:journals/corr/abs-1801-06146" class="csl-entry" role="listitem">
Howard, Jeremy, and Sebastian Ruder. 2018. <span>“Fine-Tuned Language Models for Text Classification.”</span> <em>CoRR</em> abs/1801.06146. <a href="http://arxiv.org/abs/1801.06146">http://arxiv.org/abs/1801.06146</a>.
</div>
<div id="ref-maas-EtAl:2011:ACL-HLT2011" class="csl-entry" role="listitem">
Maas, Andrew L., Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. <span>“Learning Word Vectors for Sentiment Analysis.”</span> In <em>Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies</em>, 142–50. Portland, Oregon, USA: Association for Computational Linguistics. <a href="http://www.aclweb.org/anthology/P11-1015">http://www.aclweb.org/anthology/P11-1015</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../intro.html" class="pagination-link" aria-label="Introduction">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Introduction</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../references.html" class="pagination-link" aria-label="References">
        <span class="nav-page-text">References</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>