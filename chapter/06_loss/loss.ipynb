{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ac8501f1-da7c-413a-ba7b-2ab7d1c29c9e",
   "metadata": {},
   "source": [
    "---\n",
    "title: What's in a loss?\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fcce88-30da-404c-935c-10f522954f44",
   "metadata": {},
   "source": [
    "Last chapter we implemented a [decision tree](../05_decision_tree/decision_tree.ipynb). Our decision tree performed slightly different than the `sklearn` decision tree. This is in part due to the difference between loss functions used by these models.\n",
    "\n",
    "A loss function is a way to compare model predictions to actual values. That should sound familiar. We've been using accuracy to compare model predictions to actual values from the start. Loss functions are used during model training to _tell the model how it's doing_, allowing the learning algorithm to adjust the model accordingly and make it better.\n",
    "\n",
    "We've used accuracy to train and benchmark our models but in practice accuracy is usually used as a benchmarking metric and not for training. There's nothing wrong with using accuracy as a loss function, especially with rule based models like what we've been working with, but as we move towards neural networks, more effective loss functions become possible.\n",
    "\n",
    "We will implement a different loss function for our decision tree in this chapter, not because this new loss function is better, but because it's important to understand that there's nothing magical about the loss function _as long as it's informative for the model!_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec512fba-917a-4c1c-a747-5491868a3620",
   "metadata": {},
   "source": [
    "# Loss so far\n",
    "\n",
    "A brief refresh on how our loss function works. We construct a binary tree by repeatedly splitting the data on a feature value where all data points less than that value are in one branch and all data points greater than that value are in the other branch. The best feature value to split the data on is determined by the accuracy of the branches. If the accuracy of all the data points is better than the accuracy of the branches identified from the best feature value, then binary tree construction on that set of data points stops.\n",
    "\n",
    "We've done all the hard work. Changing the loss function is easy, it's just a matter of swapping out accuracy for an alternative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ed368-207e-4273-be67-8666cb81b6f3",
   "metadata": {},
   "source": [
    "# Gini impurity\n",
    "\n",
    "The Gini impurity is the typical loss function I've seen used by decision trees. In order to understand this loss function you need to understand probability. But you already understand probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b108e5-4b01-4535-b5c0-0fc14d81fff4",
   "metadata": {},
   "source": [
    "## Probability\n",
    "\n",
    "Think back to our [baseline classifier](../02_baseline/baseline_classifier.ipynb) which always predicted the most common label in the training set. What is the accuracy of that model on the same training set? It is the ratio of the most common label over all labels. That happens to be the probability of the most common label.\n",
    "\n",
    "At its core probability is asking the question, \"how likely is event X going to happen?\" It's commonly taught using simple scenarios because it's easy to grasp. Flip a coin. What's the chance it will be heads? 1/2. Roll a die. What's the chance it will be 2? 1/6. Play the lotto. What's the chance you will win? Very, very small.\n",
    "\n",
    "That's all you need to know really and now we can implement the Gini impurity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e18cd4-a087-46a2-847d-4dd1b29ae108",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "We have a bunch of reviews. They have positive (1) or negative (0) labels. The Gini impurity is the probability of a positive label times the probability of _not_ a positive label plus the probability of a negative label times the probability of _not_ a negative label. That's a mouthful. Maybe we should start over and work up piece by piece with something more concrete.\n",
    "\n",
    "Let's say 75% of the reviews are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e65d543-221f-42da-b2ad-d942015a17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_prob = 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a1a5c-6b10-405e-9528-4a5c63ac9cdb",
   "metadata": {},
   "source": [
    "The thing about probability is there is a 100% chance of some outcome. In our case the review must be positive or negative, so if 75% of the reviews are positive then the rest must be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc4fd201-1f77-42fe-921d-991f5aa25092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative_prob = 1 - positive_prob\n",
    "negative_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfab60f-78b9-4a9e-ac64-64149c37dc24",
   "metadata": {},
   "source": [
    "Now let's compute the Gini impurity using these numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae9caed-fd12-45b8-a524-96f40e0b7210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    positive_prob * (1 - positive_prob)\n",
    "    + negative_prob * (1 - negative_prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4177bce5-b008-4358-b15c-2a8f66fcf894",
   "metadata": {},
   "source": [
    "Wait a second. This is just the positive probability times the negative probability twice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afba8bd3-7b90-49e0-90b0-15d1236d0592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_prob * negative_prob + negative_prob * positive_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263f335-4f6f-4ba7-9ad6-0aca487340ba",
   "metadata": {},
   "source": [
    "Can't we just multiply the positive and negative probabilities once and be done with it? It will work the same as a loss function either way.\n",
    "\n",
    "But does it matter when we look at 3 or more classes? Imagine we have another category of reviews which have a neutral label and say their probabilities are 50% positive, 30% negative, and 20% neutral. That will give us this gini impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66cb163d-dd86-4994-8f9a-8afb7a0927b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_prob, negative_prob, neutral_prob = 0.5, 0.3, 0.2\n",
    "(\n",
    "    positive_prob * (1 - positive_prob)\n",
    "    + negative_prob * (1 - negative_prob)\n",
    "    + neutral_prob * (1 - neutral_prob)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d6635d-dd0f-4210-b925-199d17f1b29f",
   "metadata": {},
   "source": [
    "Let's go back to the earlier definition.\n",
    "\n",
    "> The Gini impurity is the probability of a positive label times the probability of not a positive label...\n",
    "\n",
    "In the binary classification problem (two labels) the probability of \"not a positive label\" is just the probability of a negative label, but in the ternary classification problem (three labels) the probability of \"not a positive label\" is the probability of a _negative or neutral_ label. Our above equation can be rewritten as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab53579-2cd1-4625-89b9-b2bc94939fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    positive_prob * (negative_prob + neutral_prob)\n",
    "    + negative_prob * (positive_prob + neutral_prob)\n",
    "    + neutral_prob * (positive_prob + negative_prob)\n",
    ")\n",
    "# We can further simplify the above equation.\n",
    "# 1.\n",
    "(\n",
    "    positive_prob * negative_prob\n",
    "    + positive_prob * neutral_prob\n",
    "    + negative_prob * positive_prob\n",
    "    + negative_prob * neutral_prob\n",
    "    + neutral_prob * positive_prob\n",
    "    + neutral_prob * negative_prob\n",
    ")\n",
    "# 2.\n",
    "(\n",
    "    2 * positive_prob * negative_prob\n",
    "    + 2 * positive_prob * neutral_prob\n",
    "    + 2 * negative_prob * neutral_prob\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8d07e6-c9e4-44a0-be2c-91f5504834ed",
   "metadata": {},
   "source": [
    "After expanding the terms and simplifying the equation we still see each combination of probabilities twice. Again I assert we can multiply them just once and our loss function will work the same.\n",
    "\n",
    "But there is a trend. As we add more labels, we must multiply each combination of labels. This will result in exponentially more terms as the number of labels increases. If we use the first form of the Gini impurity we end up with a linearly increasing number of terms as the number of labels increases. From a practical standpoint this doesn't make a big difference as most classification problems have a limited number of labels, but it's very easy to code the first form of the Gini impurity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86b18a83-7308-43c9-a3eb-b4da16313ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.375, 0.62)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini(probabilities):\n",
    "    return sum(p * (1 - p) for p in probabilities)\n",
    "\n",
    "\n",
    "gini([0.75, 0.25]), gini([0.5, 0.3, 0.2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882db99e-600e-47ac-8666-4723d8c8c3ff",
   "metadata": {},
   "source": [
    "## Gini impurity vs accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18bbf7d3-02d3-43fd-b768-696f1f7b15b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: code up plot showing gini vs accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
