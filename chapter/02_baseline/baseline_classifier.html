<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>2&nbsp; Baseline: gotta start somewhere – NLP: From Simple to Spectacular</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../chapter/03_oner/oner.html" rel="next">
<link href="../../chapter/01_data/data.html" rel="prev">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-cd7de1037569933fbb609f06423bd096.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="../../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">


</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../chapter/02_baseline/baseline_classifier.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Baseline: gotta start somewhere</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../../">NLP: From Simple to Spectacular</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Welcome</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapter/01_data/data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Machine learning needs data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapter/02_baseline/baseline_classifier.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Baseline: gotta start somewhere</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapter/03_oner/oner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">OneR</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapter/04_oner/oner.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OneR, TwoR, RedR, BlueR: Inputs matter</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapter/05_decision_tree/decision_tree.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">More rules with Decision Trees</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapter/bonus/cleaning_data/cleaning_data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Bonus: cleaning data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../chapter/bonus/quality_vs_quantity/quality_vs_quantity.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Bonus: quality vs.&nbsp;quantity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-machine-learning" id="toc-what-is-machine-learning" class="nav-link active" data-scroll-target="#what-is-machine-learning"><span class="header-section-number">2.1</span> What is machine learning?</a>
  <ul class="collapse">
  <li><a href="#the-learning-process" id="toc-the-learning-process" class="nav-link" data-scroll-target="#the-learning-process"><span class="header-section-number">2.1.1</span> The learning process</a></li>
  </ul></li>
  <li><a href="#the-simplest-of-models" id="toc-the-simplest-of-models" class="nav-link" data-scroll-target="#the-simplest-of-models"><span class="header-section-number">2.2</span> The simplest of models</a></li>
  <li><a href="#easy-button" id="toc-easy-button" class="nav-link" data-scroll-target="#easy-button"><span class="header-section-number">2.3</span> Easy button</a>
  <ul class="collapse">
  <li><a href="#scikit-learn" id="toc-scikit-learn" class="nav-link" data-scroll-target="#scikit-learn"><span class="header-section-number">2.3.1</span> scikit-learn</a></li>
  </ul></li>
  <li><a href="#metrics-metrics-metrics" id="toc-metrics-metrics-metrics" class="nav-link" data-scroll-target="#metrics-metrics-metrics"><span class="header-section-number">2.4</span> Metrics, metrics, metrics</a>
  <ul class="collapse">
  <li><a href="#accuracy" id="toc-accuracy" class="nav-link" data-scroll-target="#accuracy"><span class="header-section-number">2.4.1</span> Accuracy</a></li>
  <li><a href="#other-metrics" id="toc-other-metrics" class="nav-link" data-scroll-target="#other-metrics"><span class="header-section-number">2.4.2</span> Other metrics</a></li>
  </ul></li>
  <li><a href="#train-vs.-test-datasets" id="toc-train-vs.-test-datasets" class="nav-link" data-scroll-target="#train-vs.-test-datasets"><span class="header-section-number">2.5</span> Train vs.&nbsp;test datasets</a></li>
  <li><a href="#preprocessing" id="toc-preprocessing" class="nav-link" data-scroll-target="#preprocessing"><span class="header-section-number">2.6</span> Preprocessing</a></li>
  <li><a href="#rolling-our-own" id="toc-rolling-our-own" class="nav-link" data-scroll-target="#rolling-our-own"><span class="header-section-number">2.7</span> Rolling our own</a></li>
  <li><a href="#sec-scikit-learnifying-our-model" id="toc-sec-scikit-learnifying-our-model" class="nav-link" data-scroll-target="#sec-scikit-learnifying-our-model"><span class="header-section-number">2.8</span> scikit-learnifying our model</a>
  <ul class="collapse">
  <li><a href="#scikit-learn-best-practices" id="toc-scikit-learn-best-practices" class="nav-link" data-scroll-target="#scikit-learn-best-practices"><span class="header-section-number">2.8.1</span> scikit-learn best practices</a></li>
  </ul></li>
  <li><a href="#multiclass-classification" id="toc-multiclass-classification" class="nav-link" data-scroll-target="#multiclass-classification"><span class="header-section-number">2.9</span> Multiclass classification</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Baseline: gotta start somewhere</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>We’ll start simple. So simple you may wonder if it’s AI at all. When building models from scratch, I like to start with the easiest thing possible and iterate. Before we write any code, let’s define what machine learning and machine learning models are.</p>
<section id="what-is-machine-learning" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="what-is-machine-learning"><span class="header-section-number">2.1</span> What is machine learning?</h2>
<p>Machine learning is a field of artificial intelligence focused on algorithms that 1) learn from data and 2) generalize to unseen data. There are three main components to machine learning, data, models, and algorithms. Machine learning models are the things that do the learning and the algorithms direct the models learning. The lines blur at times between models and algorithms and some algorithms only work for some models. At their core, models are functions. They take an input, process them in some way, and return an output. Models have learnable parameters and machine learning algorithms focus on adjusting these parameters to make the model produce better outputs.</p>
<p>Conceptually, models are simple. Take the equation for a line, <code>f(x) = m*x + b</code>. This is a model where <code>m</code> and <code>b</code> are constant values indicating the slope and y-intercept of the line. <code>x</code> is an input value and the output is <code>f(x) = y</code>. If we know <code>m</code> and <code>b</code> we can compute <code>y</code> for any <code>x</code>. Machine learning comes to the rescue when we don’t know <code>m</code> and <code>b</code>. Assuming we have a bunch of <code>(x, y)</code> points, a machine learning algorithm can guess what good values for <code>m</code> and <code>b</code> are based on those points. Then we freeze those values and the model can predict <code>y</code> for any <code>x</code>.</p>
<p>Models can be giant equations and it’s easy to get lost in the details, but remember <em>it’s still just an equation!</em> The learning algorithm will find the right constant terms for us. It’s our job to set up the problem for the algorithm and model and then get out of the way so the machine can learn.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>In machine learning, the constant terms of the equation are called parameters or weights. During training they are not constant as the learning algorithm is trying to find their optimal values, but once training is done these values become constant and you’re left with a normal equation.</p>
</div>
</div>
<section id="the-learning-process" class="level3" data-number="2.1.1">
<h3 data-number="2.1.1" class="anchored" data-anchor-id="the-learning-process"><span class="header-section-number">2.1.1</span> The learning process</h3>
<p>At it’s core the learning process iterates through prediction, comparison, and tweaking the model parameters. The training data is used in this process. We initialize the model, then use it as is to predict the outputs on the training data. These outputs are compared to the actual outputs, or targets, of the training data. If we are happy with the comparison, training is done. Otherwise the model parameters are adjusted and the process begins again. This whole process is outlined below.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class="figure"><p></p>
<div>
<pre class="mermaid mermaid-js">flowchart TB
  B[Predict output for train data] --&gt; C[Compare predictions to targets]
  C --&gt; D{Predictions good enough?}
  D -- No --&gt; E[Update model]
  D -- Yes --&gt; F[Freeze model for production]
  E --&gt; B
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</section>
</section>
<section id="the-simplest-of-models" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="the-simplest-of-models"><span class="header-section-number">2.2</span> The simplest of models</h2>
<p>Turning our attention back to our model, the simplest thing we can do is predict the same thing for every input. And if we’re going to predict the same thing for every input, it should be the most common thing.</p>
<p>This may seem silly, but it gives us a measuring stick to compare to other models. If we use the latest and greatest techniques in deep learning, it should outperform this model. The only way we’ll know it outperforms it is by building the model and testing it. If it doesn’t outperform this model, that raises cause for concern and the results should be investigated. So we start simple and incrementally improve until we are satisfied.</p>
</section>
<section id="easy-button" class="level2 page-columns page-full" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="easy-button"><span class="header-section-number">2.3</span> Easy button</h2>
<p>Throughout this book the first model in each chapter will be an existing implementation, where possible, that we can get up and running immediately. Then we’ll implement the model ourselves to get a deeper understanding of what’s going on.</p>
<section id="scikit-learn" class="level3 page-columns page-full" data-number="2.3.1">
<h3 data-number="2.3.1" class="anchored" data-anchor-id="scikit-learn"><span class="header-section-number">2.3.1</span> scikit-learn</h3>
<p><a href="https://scikit-learn.org/stable/index.html"><code>scikit-learn</code></a> is a widely used machine learning library. It comes fully loaded with all kinds of models and tools that let machine learning practitioners build models in just a few lines of code. And it turns out <code>scikit-learn</code> provides the simple model we want already as <code>sklearn.dummy.DummyClassifier</code>. This model is also referred to as a baseline model. Let’s train it.</p>
<div id="902de930-c643-409e-bf94-0b310d3f7f8c" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1"></a><span class="im">from</span> sklearn.dummy <span class="im">import</span> DummyClassifier</span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="im">from</span> nlpbook <span class="im">import</span> get_train_test_data</span>
<span id="cb1-3"><a href="#cb1-3"></a></span>
<span id="cb1-4"><a href="#cb1-4"></a>train_df, test_df <span class="op">=</span> get_train_test_data()</span>
<span id="cb1-5"><a href="#cb1-5"></a>X, y <span class="op">=</span> train_df[[<span class="st">"review"</span>]], train_df[<span class="st">"label"</span>]</span>
<span id="cb1-6"><a href="#cb1-6"></a>cls <span class="op">=</span> DummyClassifier().fit(X, y)</span>
<span id="cb1-7"><a href="#cb1-7"></a>cls.score(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>0.500803083841953</code></pre>
</div>
</div>
<p>In four lines of code, we load the dataset, train the model, and evaluate it. Don’t worry if it doesn’t make sense, we’ll go through it line by line.</p>
<section id="load-the-data" class="level4 page-columns page-full" data-number="2.3.1.1">
<h4 data-number="2.3.1.1" class="anchored" data-anchor-id="load-the-data"><span class="header-section-number">2.3.1.1</span> Load the data</h4>
<p>The first two lines load and prepare the data for training.</p>
<div id="aef5a8a7-d89c-479f-9acf-b27b3592dfcc" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1"></a>train_df, test_df <span class="op">=</span> get_train_test_data()</span>
<span id="cb3-2"><a href="#cb3-2"></a>X, y <span class="op">=</span> train_df[[<span class="st">"review"</span>]], train_df[<span class="st">"label"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>This book’s companion Python package, <code>nlpbook</code>, comes with a helper function <code>get_train_test_data</code> which cleans up the data and returns it. Then the inputs and outputs for training are separated into their own variables, <code>X</code> and <code>y</code>, respectively. What do these inputs and outputs look like? In <a href="../01_data/data.html#sec-classification-dataset" class="quarto-xref"><span>Section 1.2</span></a> we saw the <code>review</code> column contains the review, this is our input. And the <code>label</code> column is a binary value, <code>0</code> or <code>1</code>, indicating if the review is negative or positive. There is something interesting going on with <code>X</code> though, why do we use double square brackets when accessing the <code>review</code> column? The double square bracket notation tells <code>pandas</code> to return a <code>DataFrame</code> instead of a <code>Series</code>, which begs another question, why a <code>DataFrame</code> instead of a <code>Series</code>?</p>
<div class="page-columns page-full"><p>A <code>DataFrame</code> is basically a matrix, while a <code>Series</code> is an array. In machine learning, inputs can have more than one feature and many algorithms and libraries expect inputs to be in the form of a matrix where the rows of the matrix are data points and the columns are features of each data point.</p><div class="no-row-height column-margin column-container"><span class="margin-aside"><code>DataFrame.shape</code> shows the dimensions of the matrix as <code>(rows, columns)</code>.</span></div></div>
<div id="e7bf4d70-1a14-48b3-a206-de69e5d03863" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1"></a>X.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<pre><code>(24904, 1)</code></pre>
</div>
</div>
<p>In our case, we have 24,904 data points and each data point has one feature. That feature is the review. In practice, you’ll use a matrix as input, even if you only have one feature.</p>
<p>Moving on to the output, why isn’t <code>y</code> a matrix? Well it could be depending on your use case, but most of the time you will be predicting one value, so standard practice is to use an array. Each value in <code>y</code> corresponds to the output of each row in <code>X</code>. So, the first value in <code>y</code> is the output for the first row in <code>X</code>, the second value in <code>y</code> is the output for the second row in <code>X</code>, and so on.</p>
</section>
<section id="train-the-model" class="level4" data-number="2.3.1.2">
<h4 data-number="2.3.1.2" class="anchored" data-anchor-id="train-the-model"><span class="header-section-number">2.3.1.2</span> Train the model</h4>
<p>This line initializes the model and train it.</p>
<div id="116aaafa-c6af-436e-9f5b-0143deef8bdd" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1"></a>cls <span class="op">=</span> DummyClassifier().fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>With <code>scikit-learn</code> you’ll see a few methods over and over again, <code>fit</code> is one of those methods. <code>fit</code> just means train the model. We are “fitting” the model to the data. <code>scikit-learn</code> models returns <code>self</code> from <code>fit</code>, so we can initialize the model and train it in one line.</p>
</section>
<section id="evaluate-the-model" class="level4" data-number="2.3.1.3">
<h4 data-number="2.3.1.3" class="anchored" data-anchor-id="evaluate-the-model"><span class="header-section-number">2.3.1.3</span> Evaluate the model</h4>
<p>Finally the model is evaluated with <code>score</code>.</p>
<div id="1848bb5b-4952-4a8d-92b2-9031e4eec501" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1"></a>cls.score(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>0.500803083841953</code></pre>
</div>
</div>
<p>What is this score though? It’s a metric that evaluates the performance of the model.</p>
</section>
</section>
</section>
<section id="metrics-metrics-metrics" class="level2 page-columns page-full" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="metrics-metrics-metrics"><span class="header-section-number">2.4</span> Metrics, metrics, metrics</h2>
<p>Metrics give a sense of how well your model is doing. They allow you to measure and compare models. There is no one size fits all metric, and you’ll usually want to look at multiple metrics when evaluating models. I recommend starting with the end when picking metrics. Why are you building this model in the first place? What is it you want the model to do? Then define your metrics with that objective in mind.</p>
<section id="accuracy" class="level3 page-columns page-full" data-number="2.4.1">
<h3 data-number="2.4.1" class="anchored" data-anchor-id="accuracy"><span class="header-section-number">2.4.1</span> Accuracy</h3>
<p>We are trying to predict the sentiment of movie reviews. We don’t care about positive vs negative, we just care that we get it right. It’s a simple question, “How many predictions are correct?” This is accuracy. It’s measured as a ratio, the number of correct predictions over all predictions.</p>
<div id="4430b735-c32b-4446-a82f-9769f4a0cd2b" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb9-2"><a href="#cb9-2"></a></span>
<span id="cb9-3"><a href="#cb9-3"></a><span class="kw">def</span> accuracy(y, y_pred):</span>
<span id="cb9-4"><a href="#cb9-4"></a>    <span class="co"># Convert to numpy arrays for convenience.</span></span>
<span id="cb9-5"><a href="#cb9-5"></a>    y, y_pred <span class="op">=</span> np.array(y), np.array(y_pred)</span>
<span id="cb9-6"><a href="#cb9-6"></a>    <span class="co"># Create an array of boolean values indicating if</span></span>
<span id="cb9-7"><a href="#cb9-7"></a>    <span class="co"># `y` and `y_pred` are the same at each index.</span></span>
<span id="cb9-8"><a href="#cb9-8"></a>    is_equal <span class="op">=</span> y <span class="op">==</span> y_pred</span>
<span id="cb9-9"><a href="#cb9-9"></a>    <span class="co"># Sum the `True` values.</span></span>
<span id="cb9-10"><a href="#cb9-10"></a>    correct <span class="op">=</span> np.<span class="bu">sum</span>(is_equal)</span>
<span id="cb9-11"><a href="#cb9-11"></a>    <span class="co"># Return the ratio of correct over total.</span></span>
<span id="cb9-12"><a href="#cb9-12"></a>    <span class="cf">return</span> correct <span class="op">/</span> <span class="bu">len</span>(y)</span>
<span id="cb9-13"><a href="#cb9-13"></a></span>
<span id="cb9-14"><a href="#cb9-14"></a>accuracy([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="1">
<pre><code>np.float64(0.6666666666666666)</code></pre>
</div>
</div>
<p>In the simple example above there are two lists where the difference between them is at the first element. Two out of three are the same and that’s exactly what accuracy tells us.</p>
<p>In practice, we don’t have to write our own accuracy function because <code>scikit-learn</code> offers one.</p>
<div id="f4e68915-fd34-402d-97e4-c6ee514464fb" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb11-2"><a href="#cb11-2"></a></span>
<span id="cb11-3"><a href="#cb11-3"></a><span class="co"># Check our accuracy function returns the same value as `sklearn`s.</span></span>
<span id="cb11-4"><a href="#cb11-4"></a>accuracy([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>]) <span class="op">==</span> accuracy_score([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>], [<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>np.True_</code></pre>
</div>
</div>
<p>Back to our classifier! When we ran <code>cls.score(X, y)</code>, the model returned the accuracy. We can check this by computing the accuracy ourselves.</p>
<div id="c28bb10a-1296-49b1-a70b-8e6c8ab31c43" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1"></a>predictions <span class="op">=</span> cls.predict(train_df)</span>
<span id="cb13-2"><a href="#cb13-2"></a>accuracy_score(y, predictions), cls.score(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(0.500803083841953, 0.500803083841953)</code></pre>
</div>
</div>
<div class="page-columns page-full"><p>Our accuracy is <code>0.5</code> out of <code>1.0</code>, or 50% , which means we got half of the predictions correct. This makes sense since our dataset is half positive and half negative labels, so if we predict <code>0</code> or <code>1</code> for everything we should get half of them correct.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">The accuracy score is on a 0-1 scale where 1 means 100% accuracy</span></div></div>
<section id="imbalanced-datasets-and-accuracy" class="level4 page-columns page-full" data-number="2.4.1.1">
<h4 data-number="2.4.1.1" class="anchored" data-anchor-id="imbalanced-datasets-and-accuracy"><span class="header-section-number">2.4.1.1</span> Imbalanced datasets and accuracy</h4>
<div class="page-columns page-full"><p>Metrics are not foolproof. What is “good” for one dataset may not be for another. This is why we start with the simplest possible model. Because it allows us to establish minimum benchmarking values to compare against. Let’s run through an example to show how accuracy changes with the ratio of positive to negative labels in the dataset using this simple model.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">I love <a href="https://seaborn.pydata.org/"><code>seaborn</code></a> for rapid data visualization. It can’t do everything perfectly, but it does the common things beautifully.</span></div></div>
<div id="df65063f-c199-4c18-8cdf-775299f49765" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="baseline_classifier_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<p>The accuracy of our model is 50% when we have a 50/50 ratio of positive to negative labels. As the ratio moves to either extreme however (all ones or all zeros), the accuracy goes up until it reaches 100% when all the labels in the dataset are the same.</p>
<p>Intuitively a higher accuracy is better, but it might not be high because your model works well. It could be that your dataset is imbalanced and your model has figured that out and predicts everything to be the majority class. In that scenario, you end up with a fancy model you put all this effort into just to get the same result as the simple model we just made. How do you combat this? By doing what we’ve done here and start with a simple model. Then as you develop more complex models, they can be compared to this simple model to see if they make improvements!</p>
</section>
</section>
<section id="other-metrics" class="level3" data-number="2.4.2">
<h3 data-number="2.4.2" class="anchored" data-anchor-id="other-metrics"><span class="header-section-number">2.4.2</span> Other metrics</h3>
<p>Accuracy is not the only thing we can measure, but for simplicities sake it will be the only thing we measure in this book. Other common metrics we could look at are F1-score and Matthews Correlation Coefficient (MCC), but there’s plenty more.</p>
</section>
</section>
<section id="train-vs.-test-datasets" class="level2 page-columns page-full" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="train-vs.-test-datasets"><span class="header-section-number">2.5</span> Train vs.&nbsp;test datasets</h2>
<div class="page-columns page-full"><p>We’ve trained a model and evaluated it’s accuracy so now we can move on to making a better model. WRONG, WE HAVEN’T EVALUATED THE MODEL!!! We checked the accuracy on the <em>training data</em> which isn’t a true evaluation of the model. We want to know how well our model works <em>on data it hasn’t seen yet</em>, which is why we have a test set. The test set is used exclusively to benchmark the performance of the model and is not used in the training process. This comes back to making models that generalize to unseen data. Models generally perform better on data they’re trained on because that data is what the model is optimized to predict for. If we use that same data to test the model, then we’ll likely be overconfident in our models predictions. When we deploy the model and it is used on new data it hasn’t seen we’ll be in for a rude awakening. So we separate our dataset into training and testing datasets. In practice care should go into how these datasets are curated, but we won’t worry about that here since I’ve already cleaned our datasets.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">I highly recommend this <a href="https://www.fast.ai/posts/2017-11-13-validation-sets.html">blog post</a> on the dangers of blindly splitting your data. It is about validation sets, but the same concepts apply to test sets.</span></div></div>
<p>So let’s evaluate our model for real.</p>
<div id="890baad5-06a2-419c-8611-c73aab8836e4" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1"></a>X_test, y_test <span class="op">=</span> test_df[[<span class="st">"review"</span>]], test_df[<span class="st">"label"</span>]</span>
<span id="cb15-2"><a href="#cb15-2"></a>cls.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>0.5011190233977619</code></pre>
</div>
</div>
<p>The accuracy is still <code>0.5</code> which makes sense. The test dataset is curated the same way as the train dataset and has a roughly 50/50 split of positive to negative labels. While the accuracy didn’t change between the train and test datasets, we have a more unbiased evaluation of our model and this is the accuracy we will aim to beat next.</p>
</section>
<section id="preprocessing" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="preprocessing"><span class="header-section-number">2.6</span> Preprocessing</h2>
<p>When we prepared our training data, we ran this code:</p>
<div id="c094d0cf-ccee-4c3f-9259-680a1128c355" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1"></a>X, y <span class="op">=</span> train_df[[<span class="st">"review"</span>]], train_df[<span class="st">"label"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>All we did was pull out the relevant columns from the dataframe, which is as simple as it gets. Preprocessing can get very complicated and we’ll explore how preprocessing impacts model performance in future chapters. One important aspect of preprocessing is the test dataset needs to be preprocessed <em>the same way</em> as the train dataset, because the model expects the data it makes predictions about to have the same form as the data it was trained on.</p>
</section>
<section id="rolling-our-own" class="level2 page-columns page-full" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="rolling-our-own"><span class="header-section-number">2.7</span> Rolling our own</h2>
<div class="page-columns page-full"><p>Now that we’ve trained a model, let’s make it ourselves. It’s as simple as you can get, majority rules.</p><div class="no-row-height column-margin column-container"><span class="margin-aside">Model implementations will include gratuitous comments explaining the code. This is a more streamlined approach that allows for covering the abstract concepts in the chapter text while giving details on implementation alongside the implementation itself.</span></div></div>
<div id="46f38b6e-d8f1-4db3-8dd0-ae11de7d1cc1" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1"></a><span class="kw">class</span> BaselineClassifier:</span>
<span id="cb18-2"><a href="#cb18-2"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb18-3"><a href="#cb18-3"></a>        <span class="co">"""Train the model with inputs `X` on labels `y`."""</span></span>
<span id="cb18-4"><a href="#cb18-4"></a>        <span class="co"># Get the unique labels and their counts.</span></span>
<span id="cb18-5"><a href="#cb18-5"></a>        labels, counts <span class="op">=</span> np.unique(y, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb18-6"><a href="#cb18-6"></a>        <span class="co"># Keep the most common label for prediction.</span></span>
<span id="cb18-7"><a href="#cb18-7"></a>        <span class="va">self</span>.prediction <span class="op">=</span> labels[np.argmax(counts)]</span>
<span id="cb18-8"><a href="#cb18-8"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb18-9"><a href="#cb18-9"></a></span>
<span id="cb18-10"><a href="#cb18-10"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb18-11"><a href="#cb18-11"></a>        <span class="co">"""Predict the labels for inputs `X`."""</span></span>
<span id="cb18-12"><a href="#cb18-12"></a>        <span class="co"># Return the most common label as the prediction for every</span></span>
<span id="cb18-13"><a href="#cb18-13"></a>        <span class="co"># input.</span></span>
<span id="cb18-14"><a href="#cb18-14"></a>        <span class="cf">return</span> np.full(<span class="bu">len</span>(X), <span class="va">self</span>.prediction)</span>
<span id="cb18-15"><a href="#cb18-15"></a></span>
<span id="cb18-16"><a href="#cb18-16"></a></span>
<span id="cb18-17"><a href="#cb18-17"></a>bc <span class="op">=</span> BaselineClassifier()</span>
<span id="cb18-18"><a href="#cb18-18"></a>bc.fit(X, y)</span>
<span id="cb18-19"><a href="#cb18-19"></a>accuracy_score(y_test, bc.predict(X_test))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>0.5011190233977619</code></pre>
</div>
</div>
<p>Beautiful, we got the same score. But wait, there’s more!</p>
</section>
<section id="sec-scikit-learnifying-our-model" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="sec-scikit-learnifying-our-model"><span class="header-section-number">2.8</span> scikit-learnifying our model</h2>
<p><code>scikit-learn</code> provides a framework to integrate your own machine learning models to leverage all the bells and whistles provided by their API. One such benefit is benchmarking. <code>scikit-learn</code> models come with a <code>score</code> method, and the default <code>score</code> method for classifiers is accuracy. By wrapping our model in <code>scikit-learn</code>s framework, we get accuracy scores (and a bunch of other stuff) for free.</p>
<section id="scikit-learn-best-practices" class="level3" data-number="2.8.1">
<h3 data-number="2.8.1" class="anchored" data-anchor-id="scikit-learn-best-practices"><span class="header-section-number">2.8.1</span> scikit-learn best practices</h3>
<p>There’s a <a href="https://scikit-learn.org/stable/developers/develop.html">pretty lengthy document</a> on developing <code>scikit-learn</code> models, but most of the advice on that page can be boiled down to a few points.</p>
<ul>
<li><code>__init__</code> is for setting attributes, not computation.</li>
<li>Every parameter for <code>__init__</code> should have a corresponding attribute.</li>
<li>Computation during training that needs to persist across method calls should be assigned to attributes with an underscore suffix.</li>
<li>The <code>fit</code> method is for training and the <code>predict</code> method is for prediction.</li>
<li><code>fit</code> should return <code>self</code>.</li>
<li><code>BaseEstimator</code> should be to the right of <code>scikit-learn</code> mixins.</li>
<li>Must accept <code>N</code> data points at once.</li>
</ul>
<p>A note on that last point, accepting multiple data points at once comes with two benefits.</p>
<ol type="1">
<li>Multiple data points can be predicted at once.</li>
<li>Operating on multiple data points at once allows for leveraging highly optimized libraries, like <code>numpy</code>, for improved speed.</li>
</ol>
<p>With a few tweaks, our <code>BaselineClassifier</code> becomes a <code>scikit-learn</code> model.</p>
<div id="64d41ba4-cf47-4989-9585-adae96071b3c" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1"></a><span class="im">from</span> sklearn.base <span class="im">import</span> BaseEstimator, ClassifierMixin</span>
<span id="cb20-2"><a href="#cb20-2"></a></span>
<span id="cb20-3"><a href="#cb20-3"></a></span>
<span id="cb20-4"><a href="#cb20-4"></a><span class="kw">class</span> BaselineClassifier(ClassifierMixin, BaseEstimator):</span>
<span id="cb20-5"><a href="#cb20-5"></a>    <span class="kw">def</span> fit(<span class="va">self</span>, X, y):</span>
<span id="cb20-6"><a href="#cb20-6"></a>        <span class="co">"""Train the model with inputs `X` on labels `y`."""</span></span>
<span id="cb20-7"><a href="#cb20-7"></a>        <span class="co"># Get the unique labels and their counts.</span></span>
<span id="cb20-8"><a href="#cb20-8"></a>        labels, counts <span class="op">=</span> np.unique(y, return_counts<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb20-9"><a href="#cb20-9"></a>        <span class="co"># Keep the most common label for prediction.</span></span>
<span id="cb20-10"><a href="#cb20-10"></a>        <span class="co"># Note we changed the `prediction` attribute to include a</span></span>
<span id="cb20-11"><a href="#cb20-11"></a>        <span class="co"># trailing suffix because it results from a computation</span></span>
<span id="cb20-12"><a href="#cb20-12"></a>        <span class="co"># that persists across method calls.</span></span>
<span id="cb20-13"><a href="#cb20-13"></a>        <span class="va">self</span>.prediction_ <span class="op">=</span> labels[np.argmax(counts)]</span>
<span id="cb20-14"><a href="#cb20-14"></a>        <span class="cf">return</span> <span class="va">self</span></span>
<span id="cb20-15"><a href="#cb20-15"></a></span>
<span id="cb20-16"><a href="#cb20-16"></a>    <span class="kw">def</span> predict(<span class="va">self</span>, X):</span>
<span id="cb20-17"><a href="#cb20-17"></a>        <span class="co">"""Predict the labels for inputs `X`."""</span></span>
<span id="cb20-18"><a href="#cb20-18"></a>        <span class="co"># Return the most common label as the prediction for every</span></span>
<span id="cb20-19"><a href="#cb20-19"></a>        <span class="co"># input.</span></span>
<span id="cb20-20"><a href="#cb20-20"></a>        <span class="cf">return</span> np.full(<span class="bu">len</span>(X), <span class="va">self</span>.prediction_)</span>
<span id="cb20-21"><a href="#cb20-21"></a></span>
<span id="cb20-22"><a href="#cb20-22"></a></span>
<span id="cb20-23"><a href="#cb20-23"></a>cls <span class="op">=</span> BaselineClassifier().fit(X, y)</span>
<span id="cb20-24"><a href="#cb20-24"></a>cls.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>0.5011190233977619</code></pre>
</div>
</div>
<p>And with that we get accuracy for free. Thanks <code>scikit-learn</code>.</p>
</section>
</section>
<section id="multiclass-classification" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="multiclass-classification"><span class="header-section-number">2.9</span> Multiclass classification</h2>
<p>Up to this point we’ve dealt with binary classification, the label is either <code>0</code> or <code>1</code>, but classification can extend to 3 or more labels. Our dataset includes ratings which we can use as multiclass labels. Fortunately, we’ve written <code>BaselineClassifier</code> to work on an arbitrary number of labels, so we should get multiclass classification for free. Let’s see what happens when we use the <code>rating</code> column instead of the <code>label</code> column.</p>
<div id="8ecf1e3d-e1bd-4b5e-8241-60422a94cfbe" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1"></a>cls <span class="op">=</span> BaselineClassifier().fit(X, train_df[<span class="st">"rating"</span>])</span>
<span id="cb22-2"><a href="#cb22-2"></a>cls.score(X_test, test_df[<span class="st">"rating"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>0.1997151576805697</code></pre>
</div>
</div>
<p>At first glance this may seem low, but if you take a second to think about it, it actually makes sense. As the number of unique labels goes up, the frequency of the majority label is more likely to go down. Let’s look at the breakdown of ratings frequency.</p>
<div id="adb197ee-ef51-4750-a6db-8a153af5fa13" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1"></a>train_df.groupby(<span class="st">"rating"</span>).size() <span class="op">/</span> <span class="bu">len</span>(train_df)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>rating
1     0.203501
2     0.091230
3     0.096852
4     0.107613
7     0.100104
8     0.120704
9     0.090548
10    0.189447
dtype: float64</code></pre>
</div>
</div>
<p>Here we see the most frequent label shows up 20% of the time, which is inline with our accuracy on the test set. Good thing we have a baseline model to orient us as we think about accuracy on binary and multiclass classification problems!</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../chapter/01_data/data.html" class="pagination-link" aria-label="Machine learning needs data">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Machine learning needs data</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../chapter/03_oner/oner.html" class="pagination-link" aria-label="OneR">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">OneR</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>