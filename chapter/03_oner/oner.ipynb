{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4d4d1481-2d73-4838-827b-ead36e720e42",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"OneR\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df9c4f7-a29c-423d-850f-40ffb8f45dc1",
   "metadata": {},
   "source": [
    "Moving beyond the [simplest model](../02_baseline/baseline_classifier.ipynb), the next step is a deep neural network. Just kidding, the next step is something slightly more complex but still very simple. OneR [@Holte1993] is such a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de484ab-31be-4e6a-8647-451c60191791",
   "metadata": {},
   "source": [
    "## The OneR algorithm\n",
    "\n",
    "Conceptually, it works on the sampe principle as the baseline model, but on feature _categories_ instead of on the whole dataset. For each category in the feature, predict the most frequent label. To implement this, we iterate over each unique category and train a baseline classifier for just that category. When predicting on new data, we look up the baseline classifier for that category and return it's prediction.\n",
    "\n",
    "### Categorical features\n",
    "\n",
    "A categorical feature is an unordered set of values. Movie genres are a good example, horror, comedy, action, etc. There is no order to a movie genre, but each value represents a type of movie. We can treat our movie reviews the same way. We'll represent each unique review as a category.\n",
    "\n",
    "## Rolling our own\n",
    "\n",
    "There is no easy button for this model, so we'll go straight to the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5e66303-7784-4baf-9915-f327a3f21cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils.validation import validate_data\n",
    "\n",
    "\n",
    "class OneR(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Find the most predictive rule.\"\"\"\n",
    "        # Sanity check on `X` and `y`.\n",
    "        X, y = validate_data(self, X, y)\n",
    "        predictors = {}\n",
    "        # Get the unique categories from the first column.\n",
    "        categories = np.unique(X[:, 0])\n",
    "        for category in categories:\n",
    "            # Create a conditional array where each index\n",
    "            # is a boolean indicating if that index in the\n",
    "            # first column of `X` is the category we're iterating\n",
    "            # over.\n",
    "            is_category = X[:, 0] == category\n",
    "            # Grab all data points and labels in this category.\n",
    "            _X = X[is_category]\n",
    "            _y = y[is_category]\n",
    "            # Train a baseline classifier on the category.\n",
    "            predictors[category] = DummyClassifier().fit(_X, _y)\n",
    "        self.predictors_ = predictors\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for inputs `X`.\"\"\"\n",
    "        # Sanity check on `X`.\n",
    "        # `reset` should be `True` in `fit` and `False` everywhere else.\n",
    "        X = validate_data(self, X, reset=False)\n",
    "        # Create an empty array that will hold the predictions.\n",
    "        rv = np.zeros(X.shape[0])\n",
    "        # Get the unique categories from the first column.\n",
    "        categories = np.unique(X[:, 0])\n",
    "        for category in categories:\n",
    "            # Create a conditional array where each index\n",
    "            # is a boolean indicating if that index in the\n",
    "            # first column of `X` is the category we're iterating\n",
    "            # over.\n",
    "            is_category = X[:, 0] == category\n",
    "            # Grab all data points in this category.\n",
    "            _X = X[is_category]\n",
    "            # Predict the label for all datapoints in `_X`.\n",
    "            predictions = self.predictors_[category].predict(_X)\n",
    "            # Assign the prediction for this category to\n",
    "            # the corresponding indices in `rv`.\n",
    "            rv[is_category] = predictions\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c54d1e-e20c-474f-909c-365b30cb1194",
   "metadata": {},
   "source": [
    "There's a lot going on here. We've added a `scikit-learn` validation function, `validate_data`. Since we're building a `sklearn` classifier we might as well take advantage of the validation functions the framework provides. While it's not necessary to use this function, I highly recommend it for a few reasons.\n",
    "\n",
    "- It checks our inputs and outputs have the right shape, a matrix and array, respectively.\n",
    "\n",
    "    We should always be operating on these shapes and raising an error otherwise. The input, `X`, passed to `predict` also needs to be the same shape as the input passed to `fit`. If it doesn't have the same number of columns this will raise and error.\n",
    "\n",
    "- It converts the type to a `numpy` or `scipy` array.\n",
    "\n",
    "    This gives consistency. Arguments to `fit` and `predict` could by `numpy` arrays, `scipy` arrays, `pandas` dataframes, `pandas` series, lists, or any number of container types. By converting them to `numpy`/`scipy` arrays we are guaranteed a predictible API for `X` and `y`.\n",
    "\n",
    "Let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ee622c-fd81-4f2c-a708-7e2be3dde2fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '\"National Lampoon Goes to the Movies\" (1981) is absolutely the worst movie ever made, surpassing even the witless \"Plan 9 from Outer Space.\" The Lampoon film unreels in three separate and unconnected vignettes, each featuring different performers. The only common thread is the total lack of any redeeming qualities.<br /><br />Well, maybe there is one. Another reviewer on this site has said that the fleeting nude shots are nice, and he\\'s right. Misses Ganzel and Dusenberry flash their assets prettily, in part one and part two, respectively. But their glamorous displays are, alas, wasted. The directors seem to have forgotten that even T&A needs a credible story to surround it, and there\\'s none in sight.<br /><br />The third segment, starring Robby Benson and Richard Widmark, is the most disgusting of the three, and an unfortunate choice as the windup of this film. Benson plays an eager-beaver young policeman, brightly reporting for his first day of duty, ready to rid the streets of evil. He is paired with an old, cynical cop played by Widmark, and when these oil-and-water partners set out on their first patrol together, we sense a possible redemption of the film\\'s earlier failures. Maybe, just maybe, the cynical old-timer will be reformed by his new partner\\'s stalwart sense of duty and loyalty. Maybe all will end happily after all. But alas, this movie heads straight for the toilet, with no redemption, no happy ending, no coherent story of any kind.<br /><br />Before \"National Lampoon Goes to the Movies,\" I thought I had already seen the worst schlock that Hollywood could possibly turn out. Unfortunately, I hadn\\'t seen the half of it.<br /><br />'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_9161/3341900254.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0moner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0moner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_9161/258435010.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m\"\"\"Find the most predictive rule.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m# Sanity check on `X` and `y`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Get the unique categories from the first column.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2957\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"estimator\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2958\u001b[0m                 \u001b[0mcheck_y_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                         \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n\u001b[1;32m   1058\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     \u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '\"National Lampoon Goes to the Movies\" (1981) is absolutely the worst movie ever made, surpassing even the witless \"Plan 9 from Outer Space.\" The Lampoon film unreels in three separate and unconnected vignettes, each featuring different performers. The only common thread is the total lack of any redeeming qualities.<br /><br />Well, maybe there is one. Another reviewer on this site has said that the fleeting nude shots are nice, and he\\'s right. Misses Ganzel and Dusenberry flash their assets prettily, in part one and part two, respectively. But their glamorous displays are, alas, wasted. The directors seem to have forgotten that even T&A needs a credible story to surround it, and there\\'s none in sight.<br /><br />The third segment, starring Robby Benson and Richard Widmark, is the most disgusting of the three, and an unfortunate choice as the windup of this film. Benson plays an eager-beaver young policeman, brightly reporting for his first day of duty, ready to rid the streets of evil. He is paired with an old, cynical cop played by Widmark, and when these oil-and-water partners set out on their first patrol together, we sense a possible redemption of the film\\'s earlier failures. Maybe, just maybe, the cynical old-timer will be reformed by his new partner\\'s stalwart sense of duty and loyalty. Maybe all will end happily after all. But alas, this movie heads straight for the toilet, with no redemption, no happy ending, no coherent story of any kind.<br /><br />Before \"National Lampoon Goes to the Movies,\" I thought I had already seen the worst schlock that Hollywood could possibly turn out. Unfortunately, I hadn\\'t seen the half of it.<br /><br />'"
     ]
    }
   ],
   "source": [
    "from nlpbook import get_train_test_data\n",
    "\n",
    "train_df, test_df = get_train_test_data()\n",
    "features = [\"review\"]\n",
    "label = \"label\"\n",
    "\n",
    "X, y = train_df[features], train_df[label]\n",
    "X\n",
    "\n",
    "oner = OneR().fit(X, y)\n",
    "oner.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ab016d-7afd-4014-8c71-1f5a87a4b40e",
   "metadata": {},
   "source": [
    "*\\*Surprised pikachu face\\** An error!? `validate_data` didn't like our inputs. Turns out `validate_data` also trys to convert `X` and `y` to numeric values and fails hard. But why?\n",
    "\n",
    "Well this is because machine learning works on numbers, not text. We've written our algorithm to work on numbers or text, but in general the `str` type isn't usable by most machine learning algorithms and `validate_data` enforces that up front. Fortunately it's not hard to convert text categories to numbers, we just assign a unique number to each category. `sklearn` even has a class to do just that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c162c1a8-02b6-4a0b-97f2-1a843c0d4ecb",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "What we've worked with so far in `scikit-learn` are estimators. These are machine learning models. `scikit-learn` has another common type of class called transformers, which transform data as the name implies. These classes are commonly used for preprocessing tasks. They do not have a `predict` method, but instead have a `transform` method. We \"train\" them with `fit` just like we would a model, but this is for consistent preprocessing and not prediction.\n",
    "\n",
    "### Transforming text to numbers\n",
    "\n",
    "`OrdinalEncoder` is the `sklearn` class for transforming categories to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84a378f4-6ff2-45c0-b161-5c5cb7205f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  300.],\n",
       "       [22675.],\n",
       "       [22956.],\n",
       "       ...,\n",
       "       [16257.],\n",
       "       [ 4455.],\n",
       "       [ 2065.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(X)\n",
    "encoder.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26571747-340c-4c49-8b43-a813cad042d4",
   "metadata": {},
   "source": [
    "Turns out transforming data is so common, there's a short hand method for fitting and transforming in one go, `fit_transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a115455a-3b5d-430b-baa1-fd3246f1a8be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  300.],\n",
       "       [22675.],\n",
       "       [22956.],\n",
       "       ...,\n",
       "       [16257.],\n",
       "       [ 4455.],\n",
       "       [ 2065.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2a415a-56f7-40a9-873b-07980b3ce593",
   "metadata": {},
   "source": [
    "Let's give our model another try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2532c7e7-9bf9-442b-9db7-64ce16919f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_ordinal = encoder.fit_transform(X)\n",
    "oner = OneR().fit(X_ordinal, y)\n",
    "oner.score(X_ordinal, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e3fe82-9d06-448e-9852-54ce2e60983a",
   "metadata": {},
   "source": [
    "That's 100% accurate! Well it's 100% accurate on our _training data_, which we don't really care about. How does it perform on our test data?\n",
    "\n",
    "### Do unto the test data as you have done unto the train data\n",
    "\n",
    "Before we can score the model on the test data, we need to apply the same transforms. Again, `sklearn` has some niceties that make it easy to enforce the same process on all data.\n",
    "\n",
    "#### Pipelines\n",
    "\n",
    "[Pipelines](https://scikit-learn.org/stable/modules/compose.html#combining-estimators) offer convenient ways to string preprocessing and models together into one object that can be trained end to end and then make predictions on different data following the same process. The input to pipelines is a sequence of transformers with an optional predictor as the last element. Once the pipeline is set up it has the same methods for training and predicting as a regular `sklearn` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "472eb374-1262-45ac-95d0-84e856faa922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;categorical_transform&#x27;, OrdinalEncoder()), (&#x27;model&#x27;, OneR())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;categorical_transform&#x27;, OrdinalEncoder()), (&#x27;model&#x27;, OneR())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OrdinalEncoder</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.OrdinalEncoder.html\">?<span>Documentation for OrdinalEncoder</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>OrdinalEncoder()</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneR</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneR()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('categorical_transform', OrdinalEncoder()), ('model', OneR())])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Layout the sequence of operations. The first element transforms\n",
    "# the categories to numbers. The second element is our model. Each\n",
    "# element is a tuple where the first element of the tuple is the\n",
    "# name of the step and the second element is the transformer or model.\n",
    "steps = [\n",
    "    (\"categorical_transform\", OrdinalEncoder()),\n",
    "    (\"model\", OneR()),\n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "# Now train the model with the original data as input.\n",
    "# No need to fit the encoder ourselves!\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0700c3-0684-40cc-9ed7-8faf739dd483",
   "metadata": {},
   "source": [
    "Now let's try predicting on one review. Our pipeline will handle the preprocessing and prediction for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d13e2f97-59d3-4d8a-80e1-f4bf80dec71c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories [\"1st watched 2/9/2008, 4 out of 10(Dir-J.S. Cardone): Sexual political thriller that doesn't really succeed in any of these areas very well except early on where there are some interesting soft-core scenes. The movie starts off portraying a couple exploring their sexual fantasies amidst their work environments or wherever and whatever suits their fancy. The couple takes an excursion to a retreat and bathhouse where they run into a woman that's willing to be a part of a three-some and fulfill some of their fantasies. At this point, we only know that this couple is well off but we don't know until they return that the fiancé is part of a well-to-do political family. The man hopes to be on the rise to the point of possibly getting a congressional seat after the marriage. They then receive a package in the mail from an anonymous source with explicit pictures of their encounter at the bath house and their qwest begins as to how and why they were filmed, who sent the package, what they want, and how to clear their names before any of this gets out. This qwest becomes an obsession that leads them deeper into seedier worlds and takes a lot of their time, to the point where their friends & family wonder what they're doing all day and why they look rundown all the time. This movie is interesting at times but drifts into ridiculousness as they personally seek out the problem instead of getting the police involved early on because of their pride. This mistake, of course, keeps the movie going. The performances are fine despite the no-name cast but the lunacy of the situation overrides and the movie starts to become ho-hum about ½ the way through. And of course, they throw in a twist at the end that defies and challenges everything that happened prior(as is the norm these days when they don't know what else to do to spice up the movie). This doesn't help this movie one bit, though.\"] in column 0 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m test_df[features], test_df[label]\n\u001b[0;32m----> 2\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/pipeline.py:785\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 785\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/utils/_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    325\u001b[0m         )\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:1597\u001b[0m, in \u001b[0;36mOrdinalEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1584\u001b[0m \u001b[38;5;124;03mTransform X to ordinal codes.\u001b[39;00m\n\u001b[1;32m   1585\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1594\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[1;32m   1595\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1596\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategories_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1597\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_category_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_missing_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1603\u001b[0m X_trans \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1605\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cat_idx, missing_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_indices\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniforge3/envs/nlp_simple_to_spectacular/lib/python3.12/site-packages/sklearn/preprocessing/_encoders.py:218\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, ensure_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle_unknown \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    214\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound unknown categories \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m in column \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m during transform\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(diff, i)\n\u001b[1;32m    217\u001b[0m     )\n\u001b[0;32m--> 218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories [\"1st watched 2/9/2008, 4 out of 10(Dir-J.S. Cardone): Sexual political thriller that doesn't really succeed in any of these areas very well except early on where there are some interesting soft-core scenes. The movie starts off portraying a couple exploring their sexual fantasies amidst their work environments or wherever and whatever suits their fancy. The couple takes an excursion to a retreat and bathhouse where they run into a woman that's willing to be a part of a three-some and fulfill some of their fantasies. At this point, we only know that this couple is well off but we don't know until they return that the fiancé is part of a well-to-do political family. The man hopes to be on the rise to the point of possibly getting a congressional seat after the marriage. They then receive a package in the mail from an anonymous source with explicit pictures of their encounter at the bath house and their qwest begins as to how and why they were filmed, who sent the package, what they want, and how to clear their names before any of this gets out. This qwest becomes an obsession that leads them deeper into seedier worlds and takes a lot of their time, to the point where their friends & family wonder what they're doing all day and why they look rundown all the time. This movie is interesting at times but drifts into ridiculousness as they personally seek out the problem instead of getting the police involved early on because of their pride. This mistake, of course, keeps the movie going. The performances are fine despite the no-name cast but the lunacy of the situation overrides and the movie starts to become ho-hum about ½ the way through. And of course, they throw in a twist at the end that defies and challenges everything that happened prior(as is the norm these days when they don't know what else to do to spice up the movie). This doesn't help this movie one bit, though.\"] in column 0 during transform"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_df[features], test_df[label]\n",
    "pipeline.predict(X_test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6902aa0-b880-4328-bce0-467e33b36fb6",
   "metadata": {},
   "source": [
    "More errors, this is becoming a theme for this chapter. The error says the `transform` method found an unknown category. It turns out there are reviews in the test set that are different from the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164b92d5-b66a-4e8c-b804-97a68ba5c5d9",
   "metadata": {},
   "source": [
    "So when `OrdinalEncoder` tries to transform unseen reviews in the test set it doesn't know what category to assign them since it was fitted on the train set. The `sklearn` developers have thought of a way to handle this though by assigning all unknown categories to one unknown value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fccb6b8-892c-4707-a73a-29ca8720b394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OrdinalEncoder(\n",
    "    handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    ")\n",
    "encoder.fit(X)\n",
    "encoder.transform(X_test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d66ac8-f214-482e-9c59-7b94dcdabfd0",
   "metadata": {},
   "source": [
    "Voila, it's fixed. But this raises another problem. Our encoder can handle unknown categories, what about our model? It can't, so we need to provide a fallback prediction for unknown categories. The simple solution is to use the baseline classifier trained on all the train data to predict unknown categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55fc1448-812f-40bd-8ba8-750aa07e65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneR(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Find the most predictive rule.\"\"\"\n",
    "        # Sanity check on `X` and `y`.\n",
    "        X, y = validate_data(self, X, y)\n",
    "        predictors = {}\n",
    "        # Get the unique categories from the first column.\n",
    "        categories = np.unique(X[:, 0])\n",
    "        for category in categories:\n",
    "            # Create a conditional array where each index\n",
    "            # is a boolean indicating if that index in the\n",
    "            # first column of `X` is the category we're iterating\n",
    "            # over.\n",
    "            is_category = X[:, 0] == category\n",
    "            # Grab all data points and labels in this category.\n",
    "            _X = X[is_category]\n",
    "            _y = y[is_category]\n",
    "            # Train a baseline classifier on the category.\n",
    "            predictors[category] = DummyClassifier().fit(_X, _y)\n",
    "        self.predictors_ = predictors\n",
    "        # Create a fallback predictor for unknown categories.\n",
    "        self.unknown_predictor_ = DummyClassifier().fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for inputs `X`.\"\"\"\n",
    "        # Sanity check on `X`.\n",
    "        # `reset` should be `True` in `fit` and `False` everywhere else.\n",
    "        X = validate_data(self, X, reset=False)\n",
    "        # Create an empty array that will hold the predictions.\n",
    "        rv = np.zeros(X.shape[0])\n",
    "        # Get the unique categories from the first column.\n",
    "        categories = np.unique(X[:, 0])\n",
    "        for category in categories:\n",
    "            # Create a conditional array where each index\n",
    "            # is a boolean indicating if that index in the\n",
    "            # first column of `X` is the category we're iterating\n",
    "            # over.\n",
    "            is_category = X[:, 0] == category\n",
    "            # Grab all data points in this category.\n",
    "            _X = X[is_category]\n",
    "            # Predict the label for all datapoints in `_X`.\n",
    "            try:\n",
    "                predictions = self.predictors_[category].predict(_X)\n",
    "            except KeyError:\n",
    "                # Fallback to the predictor for unknown categories.\n",
    "                predictions = self.unknown_predictor_.predict(_X)\n",
    "            # Assign the prediction for this category to\n",
    "            # the corresponding indices in `rv`.\n",
    "            rv[is_category] = predictions\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d9234-f0c6-4764-80f8-d35b580cef4f",
   "metadata": {},
   "source": [
    "Now we'll recreate the pipeline with our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e38073f-4964-4757-afdc-41115c789637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [\n",
    "    (\n",
    "        \"categorical_transform\",\n",
    "        OrdinalEncoder(\n",
    "            handle_unknown=\"use_encoded_value\", unknown_value=-1\n",
    "        ),\n",
    "    ),\n",
    "    (\"model\", OneR()),\n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X, y)\n",
    "pipeline.predict(X_test.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf407e41-4969-4de5-9857-377aa46385d0",
   "metadata": {},
   "source": [
    "Our model predicted the first review in the test set has a positive sentiment, which means it's predicting something, so it must be working!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bb2424-e546-465e-b06b-54874ea0c5af",
   "metadata": {},
   "source": [
    "## Evaluating our model\n",
    "\n",
    "Our preprocessing is locked in and our model is trained. Now we can score our model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "504729f6-b1fc-4999-83ea-9e170d1d75d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011190233977619"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01f2de7-2369-4e17-9e83-892cfb214f3d",
   "metadata": {},
   "source": [
    "That's a lot worse than the 100% accuracy we got on the train data. How does this compare to the baseline model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3c370ff-810a-4d70-8af8-ffcb1d027dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011190233977619"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpbook import model_results\n",
    "\n",
    "model_results[\"baseline\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71ac4de-3b29-46ef-b473-04e3d799c79d",
   "metadata": {},
   "source": [
    "Damn, that's the same accuracy as the baseline model. Why is that?\n",
    "\n",
    "Turns out all the reviews in the test set are different from the reviews in the train set, so this model devolves to the baseline model, giving us the same result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58ef0493-9ce4-43f0-a9a7-ba789b5a060e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_df[\"review\"]) & set(test_df[\"review\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f19ecca-396f-4ea0-bb1d-9f1e47c3ad9d",
   "metadata": {},
   "source": [
    "It's unfortunate we didn't see an improvement in performance, but because we are comparing to a baseline, we know where we stand. In the next chapter we'll mostly ignore the OneR algorithm and focus on improving performance by creating a richer representation of the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37055a6d-3fdb-456c-b31b-1d62e1767ae5",
   "metadata": {},
   "source": [
    "## Rolling your own transformer\n",
    "\n",
    "Much like our model, we can write transformers that slot into the `sklearn` API, all that we need to do is implement `fit` and `transform` methods. These follow all the same guidelines outlined in @sec-scikit-learnifying-our-model. Let's make our own `OrdinalEncoder` called `CategoricalEncoder`.[The `transform` method heavily uses [broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html), which is one way `numpy` speeds up operations on arrays.]{.aside}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c2f8bf17-3448-4ee5-8381-affc09804e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "class CategoricalEncoder(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Generate numeric categories from `X`.\n",
    "\n",
    "        Note: All `fit` methods must accept a `y` argument whether they\n",
    "              use them or not. Transfomers typically ignore this argument\n",
    "              whether it's passed in or not.\n",
    "        \"\"\"\n",
    "        # Validate the data as before. `skip_check_array=True` tells `validate_data` not to convert `X` to a numeric array type. This is important since we have to deal with numeric or text types.\n",
    "        X = validate_data(self, X, skip_check_array=True)\n",
    "        try:\n",
    "            # Since `validate_data` did not convert `X` to a numeric array, we need to convert it to a matrix if it's still a `DataFrame`.\n",
    "            X = X.to_numpy()\n",
    "        except AttributeError:\n",
    "            # This is not a `DataFrame`. Assume it's a `numpy` or `scipy` array.\n",
    "            pass\n",
    "\n",
    "        categories = []\n",
    "        # Iterate over each column in `X`.\n",
    "        for column in X.T:\n",
    "            # Get all unique values in the column.\n",
    "            values = np.unique(column)\n",
    "            # Store the unique values as the ith element in the array.\n",
    "            categories.append(values)\n",
    "        # Save the categories on the transformer.\n",
    "        self.categories_ = categories\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Return the categorical values.\"\"\"\n",
    "        # Validate the data as before. `skip_check_array=True` tells `validate_data` not to convert `X` to a numeric array type. This is important since we have to deal with numeric or text types.\n",
    "        X = validate_data(self, X, skip_check_array=True, reset=False)\n",
    "        try:\n",
    "            # Since `validate_data` did not convert `X` to a numeric array, we need to convert it to a matrix if it's still a `DataFrame`.\n",
    "            X = X.to_numpy()\n",
    "        except AttributeError:\n",
    "            # This is not a `DataFrame`. Assume it's a `numpy` or `scipy` array.\n",
    "            pass\n",
    "\n",
    "        # Create an array with the same shape as `X` to store the categorical values. An unknown category, `-1` is used as the default value.\n",
    "        rv = np.full(X.shape, -1)\n",
    "        # Iterate over each column in `X`.\n",
    "        for i, x in enumerate(X.T):\n",
    "            # Grab the categories for the ith column of `X`.\n",
    "            categories = self.categories_[i]\n",
    "            # Reshape the column to be a Nx1 matrix. Using a matrix instead of an array allows us to leverage `numpy` broadcasting.\n",
    "            x = x.reshape(-1, 1)\n",
    "            # Create boolean matrix where `True` values indicate the index of `categories` that equals `x` for each row.\n",
    "            is_category = x == categories\n",
    "            # Find the indices of `x` that contain known categories. This tells us which rows have known categories.\n",
    "            known_category = is_category.any(axis=1)\n",
    "            # Get the index of the `True` value in each row. This is the numeric value for the category.\n",
    "            category_value = np.where(is_category)[1]\n",
    "            # Assign the category index to the appropriate rows.\n",
    "            rv[known_category, i] = category_value\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5379990a-d812-4859-b66f-20588c817951",
   "metadata": {},
   "source": [
    "Our very first transformer! Let's run it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6f969c38-e562-4a7e-859c-ba0c2788577b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  300],\n",
       "       [22675],\n",
       "       [22956],\n",
       "       ...,\n",
       "       [16257],\n",
       "       [ 4455],\n",
       "       [ 2065]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder = CategoricalEncoder()\n",
    "cat_encoder.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308403d9-aa1b-43eb-91e7-f8206c184452",
   "metadata": {},
   "source": [
    "Beautiful, we've successfully recreated `OrdinalEncoder`. And we should get `-1` for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5964479a-143b-40cd-9195-d9de6b100207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3603d26b-f485-4684-90f4-379dd93f953f",
   "metadata": {},
   "source": [
    "Let's use it in a pipeline!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b95a04fa-0944-4744-abb4-e69adff23fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5011190233977619"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [\n",
    "    (\"categorical_transform\", CategoricalEncoder()),\n",
    "    (\"model\", OneR()),\n",
    "]\n",
    "pipeline = Pipeline(steps)\n",
    "pipeline.fit(X, y)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba8ca7-246e-4bb4-b68c-8a0482f9b13f",
   "metadata": {},
   "source": [
    "Heck yeah it worked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e04aa-8d7f-4074-a217-213fe59fcb01",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "\n",
    "We know every review in the test data will have an unknown category, so the OneR model will fallback to the baseline classifier for every review meaning we'll get the same result we did in the last chapter."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
