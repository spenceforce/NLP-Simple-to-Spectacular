{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afef2923-96a4-4a04-b84c-237b8dc26665",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"OneR, TwoR, RedR, BlueR: Inputs matter\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93200d8f-e1b0-4aee-9efe-1e66b7d6d451",
   "metadata": {},
   "source": [
    "[Last chapter](../03_oner/oner.ipynb) we implemented the OneR [@Holte1993] algorithm. In this chapter we'll improve the model without improving the model. Sounds strange, but bear with me. This chapter is all about changing the input to the model.\n",
    "\n",
    "Right now we just pass the length as input. It's a simple way to represent reviews as a number (see @sec-feature-extraction-intro). In fact it's too simple which is why our model hasn't improved from 50% accuracy. Now we will focus on creating a richer representation of the reviews for our model, one that the model can actually learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b9574-f8d0-4042-acba-886123280046",
   "metadata": {},
   "source": [
    "## Bag of characters\n",
    "\n",
    "Text data is rich in information, with the ordering of characters, words, and sentences all contributing to structure and meaning. There are several ways to capture that information and represent it as a matrix of numbers. We will start with characters as these are the foundational building blocks of words.\n",
    "\n",
    "We can count the number of each character in a review and represent that review as the count of each character. This representation is called a bag of characters and it can be extended to words, sentences, or whatever you want really. And of course `sklearn` has a way to do this with `CountVectorizer`.[`CountVectotrizer` returns a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html) which are memory efficient for matrices that contain mostly 0s.]{.aside} This class creates a `dict` mapping characters (or words) to array indices when fitting to training data. Then, when other data is transformed to a bag of characters, it counts up each character and puts them in an array at the specified indices in the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a9c5a2-74ac-47ce-98b2-9db658890d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, 275,   0,   6,   0,   0,   0,   1,   5,   1,   1,\n",
       "          0,   0,  25,   4,  16,   8,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   1,   2,   0,   0,   8,   0,   8,   0,   0,   2,   5,   0,\n",
       "          1,   0,   0,   3,   2,   3,   0,   0,   3,   5,   2,   1,   1,\n",
       "          0,   2,   1,   5,   1,   0,   3,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  99,  24,  23,  50, 166,  31,  21,  64,  84,   1,\n",
       "          5,  61,  27,  89,  92,  30,   1,  94,  90, 122,  29,  13,  17,\n",
       "          0,  35,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpbook import get_train_test_data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_df, test_df = get_train_test_data()\n",
    "\n",
    "# Create the bag of characters feature extraction transformer.\n",
    "# The `CountVectorizer` class bags input text. We set\n",
    "# `analyzer=\"char\"` so that `CountVectorizer` counts characters\n",
    "# instead of words and `lowercase=False` to prevent upper case\n",
    "# letters from being converted to lowercase.\n",
    "vectorizer = CountVectorizer(analyzer=\"char\", lowercase=False)\n",
    "\n",
    "# Fit the bag of characters transformer on our reviews.\n",
    "# Notice we do not pass a matrix into the fit method, but an array.\n",
    "# Feature extraction should be performed on a per column basis so\n",
    "# we need to pass in the column we want feature extraction performed\n",
    "# on.\n",
    "vectorizer.fit(train_df[\"review\"])\n",
    "\n",
    "# Transform the first row to a bag of characters.\n",
    "# Convert the sparse matrix to a numpy array to see the counts.\n",
    "vectorizer.transform(train_df[\"review\"].head(1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8ed55-3b53-425a-95a8-0fe924687df1",
   "metadata": {},
   "source": [
    "This is our bag of characters. Each element in this array is a count of some character. We can check what character each array element is counting with the `vocabulary_` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1892adc-36f1-448c-98e8-cfbba1393ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 5), ('N', 49), ('a', 68), ('t', 87), ('i', 76)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.vocabulary_.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb25bf1-fd4d-4087-9410-64a973c926c5",
   "metadata": {},
   "source": [
    "So index 5 of the above array is the counts for the character `\"`, index 49 is the counts for `N`, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e40f86-4691-4fd1-a0a0-cbdb2808fd5b",
   "metadata": {},
   "source": [
    "## Transformers\n",
    "\n",
    "What we've worked with so far in scikit-learn are estimators. These are machine learning models. scikit-learn has another common type of class called transformers, which transform data as the name implies. These classes are commonly used for preprocessing tasks. They do not have a predict method, but instead have a `transform` method. We \"train\" them with `fit` just like we would a model, but these objects are used for consistent preprocessing and not prediction. `CountVectorizer` is a transformer, hence the `transform` method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff638ec-a110-4463-97cb-ddfb1699bc81",
   "metadata": {},
   "source": [
    "## OneR revisited\n",
    "\n",
    "Now we can just pass this as input to our OneR model right? Not quite, our model isn't capable of handling this input yet. Here's the implementation from last chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55fc1448-812f-40bd-8ba8-750aa07e65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "\n",
    "class OneR(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train on the categories in the first column of `X`.\"\"\"\n",
    "        # Store the classes.\n",
    "        # sklearn provides a handy function `unique_labels` for this\n",
    "        # purpose. You could also use `np.unique`.\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        predictors = {}\n",
    "        # Get the unique categories from `X`.\n",
    "        categories = np.unique(X)\n",
    "        for value in categories:\n",
    "            # Create a boolean array where `True` indices indicate the\n",
    "            # rows that have this value.\n",
    "            is_value = X == value\n",
    "\n",
    "            # Grab all data points and labels with this value.\n",
    "            _X = X[is_value]\n",
    "            _y = y[is_value]\n",
    "\n",
    "            # Train a baseline classifier on the value.\n",
    "            predictors[value] = DummyClassifier().fit(_X, _y)\n",
    "\n",
    "        self.predictors_ = predictors\n",
    "\n",
    "        # Create a fallback predictor for unknown categories.\n",
    "        self.unknown_predictor_ = DummyClassifier().fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for inputs `X`.\"\"\"\n",
    "        # Create an empty array that will hold the predictions.\n",
    "        rv = np.zeros(len(X), dtype=int)\n",
    "\n",
    "        # Get the unique categories from `X`.\n",
    "        categories = np.unique(X)\n",
    "        for value in categories:\n",
    "            # Create a boolean array where `True` indices indicate the\n",
    "            # rows that have this value.\n",
    "            is_value = X == value\n",
    "\n",
    "            # Grab all data points in this value.\n",
    "            _X = X[is_value]\n",
    "\n",
    "            # Predict the label for all datapoints in `_X`.\n",
    "            try:\n",
    "                predictions = self.predictors_[value].predict(_X)\n",
    "            except KeyError:\n",
    "                # Fallback to the predictor for unknown categories.\n",
    "                predictions = self.unknown_predictor_.predict(_X)\n",
    "\n",
    "            # Assign the prediction for this value to\n",
    "            # the corresponding indices in `rv`.\n",
    "            rv[is_value] = predictions\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd4fd7-75e4-4c0a-9e94-77ffc805da36",
   "metadata": {},
   "source": [
    "Notice `X` is an array, but we are passing in a matrix from here on out. Each row will have multiple features to accomodate for each character which raises a problem. OneR works on one feature and now we have many.\n",
    "\n",
    "Previously, I said the algorithm works by predicting the most frequent label for each category. This is only half the story of the OneR algorithm. The other half of the story is it does this for _every feature_, then makes predictions based on the _best feature_. When we first implemented this model we only had one feature so it didn't matter, but now we have many, so we need to tweak the implementation to find the best feature when given any number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977b9412-fdfc-4f02-8dce-4e33d5f8bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "# Rename the `OneR` class to `Rule`.\n",
    "Rule = OneR\n",
    "\n",
    "\n",
    "# Create a new `OneR` class which finds the best `Rule` in the\n",
    "# dataset.\n",
    "class OneR(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Find the best rule in the dataset.\"\"\"\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        col_idx = score = rule = None\n",
    "\n",
    "        # Iterate over each feature.\n",
    "        # `numpy` and `scipy` iterate over rows. Rows are data points.\n",
    "        # We want the columns (features). An easy trick to iterate\n",
    "        # over columns is to transpose the matrix which flips it along\n",
    "        # its diagonal.\n",
    "        for i, column in enumerate(X.T):\n",
    "            # Convert sparse matrix to `numpy` array.\n",
    "            # `Rule` works on numpy arrays, so we should use consistent\n",
    "            # array types.\n",
    "            if scipy.sparse.issparse(column):\n",
    "                column = column.toarray()\n",
    "\n",
    "            # `column` has matrix shape (1, N) but we need array shape (N,).\n",
    "            # Use `np.squeeze` to flatten to 1D array.\n",
    "            column = column.squeeze()\n",
    "\n",
    "            # Create a rule for the ith column.\n",
    "            rule_i = Rule().fit(column, y)\n",
    "            # Score the ith columns accuracy.\n",
    "            score_i = rule_i.score(column, y)\n",
    "\n",
    "            # Keep the rule for the ith column if it has the highest\n",
    "            # accuracy so far.\n",
    "            if score is None or score_i > score:\n",
    "                rule = rule_i\n",
    "                score = score_i\n",
    "                col_idx = i\n",
    "\n",
    "        self.rule_ = rule\n",
    "        self.i_ = col_idx\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for inputs `X`.\"\"\"\n",
    "        # Get the ith column from the matrix.\n",
    "        column = X[:, self.i_]\n",
    "        # Convert sparse matrix to `numpy` array.\n",
    "        # `Rule` works on numpy arrays, so we should use consistent\n",
    "        # array types.\n",
    "        if scipy.sparse.issparse(column):\n",
    "            column = column.toarray()\n",
    "\n",
    "        # `column` has matrix shape (1, N) but we need array shape (N,).\n",
    "        # Use `np.squeeze` to flatten to 1D array.\n",
    "        column = column.squeeze()\n",
    "\n",
    "        # Return predictions for the rule.\n",
    "        return self.rule_.predict(column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4d689-7a55-452f-8616-cbb2a1e7a92c",
   "metadata": {},
   "source": [
    "And now we can train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471abf36-f1a1-477c-a736-90b4a65db906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneR</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneR()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "OneR()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "# Grab `X` and `y`.\n",
    "features = \"review\"\n",
    "labels = \"label\"\n",
    "X, y = train_df[features], train_df[labels]\n",
    "\n",
    "# Create the bag of characters transform.\n",
    "bag_of_chars = CountVectorizer(analyzer=\"char\", lowercase=False)\n",
    "\n",
    "# Create the model.\n",
    "oner = OneR()\n",
    "\n",
    "# Fit the model.\n",
    "# We use `fit_transform` on the `CountVectorizer` to simultaneously\n",
    "# fit the transformer on the training data, then transform that\n",
    "# data all in one go.\n",
    "oner.fit(bag_of_chars.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194628a-ddf7-4663-b292-45cb33570569",
   "metadata": {},
   "source": [
    "After all that work, how'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "170d1dfe-dcea-4fa5-9f14-68dcba741a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5812817904374364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = test_df[features], test_df[labels]\n",
    "oner.score(bag_of_chars.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf0ea4-88db-4525-8f39-efbe397a03d8",
   "metadata": {},
   "source": [
    "58% accuracy, that's a big improvement over the 50% accuracy of our baseline and original OneR models! All we did was change the input to the OneR model and we gained an 8% bump in accuracy, how awesome is that?\n",
    "\n",
    "## Machine learning is an end to end process\n",
    "\n",
    "We barely touched the model and ended up with an 8% improvement just by improving the preprocessing step. There are multiple steps to building a model, from collecting data through model training and they are all important for the final outcome. I probably sound like a broken record at this point, but this is why we started with a baseline model. The process of building a model is really one of experimentation. You make a change here then test it. Now a change there and test it. It's tweak after tweak, but you need to know how those tweaks affect the performance to know if they really matter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345bd59-9b6b-4167-9423-760baaba898e",
   "metadata": {},
   "source": [
    "## Models as analysis tools {#sec-models-as-analysis-tools}\n",
    "\n",
    "Now that we've trained a model that actually has some predictive power, we can start to use it for interesting things. Often we use models to predict outcomes, but we can also go in the other direction and use them to learn about our data. OneR found some character that is predictive for our data. What is that character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919b257a-0743-4d82-9354-4305f9585ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the index of the rule.\n",
    "bag_idx = oner.i_\n",
    "\n",
    "# Grab the vocabulary from the fitted bag of characters.\n",
    "vocab = bag_of_chars.vocabulary_\n",
    "\n",
    "# Find the character associated with the index.\n",
    "[char for char, char_idx in vocab.items() if char_idx == bag_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc17a5e-1e00-4874-90d5-0f301626e618",
   "metadata": {},
   "source": [
    "Interesting, question marks are the most important character for determining labels. My hypothesis is more question marks means a bad review. We can visualize this with a count plot (or histogram) to see how the number of question marks impacts the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6ddb47-7ff6-4ea0-9a49-9f5d6ec46eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='?', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = train_df.copy()\n",
    "data[\"?\"] = data[\"review\"].str.count(\"\\\\?\")\n",
    "sns.countplot(data, x=\"?\", hue=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c72a5-600f-4cdb-bb60-34a515992372",
   "metadata": {},
   "source": [
    "Ah, so if there are no question marks, the review is more likely to be positive. Inversely we can say if the review contains a question, it's likely the review is negative.\n",
    "\n",
    "Instead of analyzing the data ourselves to find which characters are associated with positive or negative reviews, our model did the analysis for us. We let the model learn about the data, then in turn we leveraged what the model learned to gain an insight into the data. As we make better models and richer representations of the input text, the amount of information the model can tell us about the data will increase as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d47e4d0-0a10-4f04-9758-b3066949fc94",
   "metadata": {},
   "source": [
    "## Pipelines\n",
    "\n",
    "Before we dig in to a bag of characters implementation, this is a good time to learn about pipelines. Machine learning is an end to end process, and pipelines are a way to encapsulate that process in scikit-learn.[Pipelines are common patterns outside of scikit-learn as well. It's really a way to string processes together in a nice, repeatable way.]{.aside} Whenever we perform preprocessing, the preprocessor must be fit to the training data, then the training data is transformed, and finally passed to the model for training. Then during prediction, the data must be transformed the same way before being passed to the model. Preprocessing can become very complicated with multiple preprocessors working on the data before it is handed off to the model for training. If we forget one preprocessing step during prediction, the model could throw an error, or worse it can silently fail and suffer poor performance. Pipelines prevent this from occuring by ensuring that the steps taken during training are repeated during prediction.\n",
    "\n",
    "Let's make a pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66884d01-2aac-4b7a-a3a5-53c16a530ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5812817904374364"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a new preprocessor and model.\n",
    "boc = CountVectorizer(analyzer=\"char\", lowercase=False)\n",
    "oner = OneR()\n",
    "\n",
    "# Outline the steps for the pipeline.\n",
    "# This is an array of tuples where each tuple is a step.\n",
    "# Each tuple contains the name of the step as the first\n",
    "# element (we can name these steps whatever we like) and\n",
    "# the estimator/transformer as the second element.\n",
    "steps = [(\"boc\", boc), (\"OneR\", oner)]\n",
    "\n",
    "# Set up the pipeline.\n",
    "pipeline = Pipeline(steps)\n",
    "\n",
    "# Train and score the pipeline.\n",
    "pipeline.fit(X, y)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82217dbc-a52f-4fbb-942d-a55a98da4733",
   "metadata": {},
   "source": [
    "Nice, that gave the same result and we didn't have to remember to apply the preprocessing transform to the test data. One thing to note about pipelines is all but the last step need to have a `transform` method. The last step needs a `predict` method. Basically pipelines string together transformers, then pass the output of that process to the last step which is a model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae2743a-6da1-41e4-b365-69114f8d9fbe",
   "metadata": {},
   "source": [
    "## Rolling our own feature extractor {#sec-rolling-our-own-boc}\n",
    "\n",
    "We've already handled the OneR model, now let's make a bag of characters transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf2ff2f-ef6e-4a8d-b3cf-a54f4dbeeb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class BagOfChars(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Bag of characters feature extractor.\"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit on all characters in the array `X`.\n",
    "\n",
    "        Note: `X` should be a 1d array.\n",
    "        \"\"\"\n",
    "        # We want a 1d text array so we'll check its shape here.\n",
    "        # While iterating over the array values we'll check\n",
    "        # they are text while trying to extract characters.\n",
    "        assert len(X.shape) == 1\n",
    "\n",
    "        vocabulary_ = {}\n",
    "        # Iterate over each string in the array.\n",
    "        for x in X:\n",
    "            # Check it's a string!\n",
    "            assert isinstance(x, str)\n",
    "\n",
    "            # Get the unique characters in the string.\n",
    "            chars = np.unique(list(x))\n",
    "\n",
    "            # Add each character to the vocabulary if it isn't\n",
    "            # there already.\n",
    "            for char in chars:\n",
    "                if char not in vocabulary_:\n",
    "                    vocabulary_[char] = len(vocabulary_)\n",
    "\n",
    "        self.vocabulary_ = vocabulary_\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform `X` to a count matrix.\n",
    "\n",
    "        Note: `X` should be a 1d array.\n",
    "        \"\"\"\n",
    "        # Run our own checks.\n",
    "        assert len(X.shape) == 1\n",
    "\n",
    "        # Create a matrix to hold the counts.\n",
    "        rv = np.zeros((X.shape[0], len(self.vocabulary_)), dtype=int)\n",
    "        # Iterate over each string in the array.\n",
    "        for i, x in enumerate(X):\n",
    "            # Check it's a string!\n",
    "            assert isinstance(x, str)\n",
    "\n",
    "            # Get the unique characters in the string and their\n",
    "            # counts.\n",
    "            chars, counts = np.unique(list(x), return_counts=True)\n",
    "            # Add each character count to the count matrix\n",
    "            # for the specific row.\n",
    "\n",
    "            for char, count in zip(chars, counts):\n",
    "                # Make sure the character is part of the vocabulary,\n",
    "                # otherwise ignore it.\n",
    "                if char in self.vocabulary_:\n",
    "                    rv[i, self.vocabulary_[char]] = count\n",
    "\n",
    "        # Return the count matrix.\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2b08d-00b0-4b29-8308-ac824a80b61b",
   "metadata": {},
   "source": [
    "Let's plug it into a pipeline and see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d08c0dd-bb81-4e21-94cd-b865871bee51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5812817904374364"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boc = BagOfChars()\n",
    "oner = OneR()\n",
    "pipeline = Pipeline([(\"boc\", boc), (\"oner\", oner)])\n",
    "\n",
    "# Train it!\n",
    "pipeline.fit(X, y)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0579cf7-7050-441a-801a-5268f6d64258",
   "metadata": {},
   "source": [
    "Easy peasy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
