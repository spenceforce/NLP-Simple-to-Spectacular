{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d19f8b2c-a610-4035-8cca-0b4afe477901",
   "metadata": {},
   "source": [
    "---\n",
    "title: Machine learning needs data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63512644-d72e-4d64-8e06-8357f21b2907",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Without data, machine learning is nothing. After all what will it learn if it has nothing to learn from. Think about everything you've learned throughout your life. All the books you've read, the movies you've watched, the experiences you've lived. Everything you've touched, tasted, heard, felt, smelled. It all comes together to shape who you are and what you know. Our brains adapt and change to all of this input. Our brains _learn_. Take away all of the memories and experiences and what are we left with? Thoughts maybe, but of what? Without the context of our life there isn't much to think about. Machine learning models work like our brain, but simpler. They take data and try to make sense of it, or _learn_ from it. The more data, the easier it is to learn from, at least in theory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32238a-b6d1-49b3-bc99-0737937e9ec6",
   "metadata": {},
   "source": [
    "## The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea804c-b374-4d0b-bfe6-ec5f5c61ced3",
   "metadata": {},
   "source": [
    "Our models will be using datasets of movie reviews from IMDB [@maas-EtAl:2011:ACL-HLT2011]. The original datasets can be found at [https://ai.stanford.edu/~amaas/data/sentiment](https://ai.stanford.edu/~amaas/data/sentiment).\n",
    "\n",
    "::: {.callout-note}\n",
    "One of the most important chapters in this book is about cleaning data. It's a bonus chapter at the end. It walks through the steps and analysis I performed to clean and prepare the dataset for this book. At this point it's not important. The focus should be on building models as fast as possible and iterating on them. By the end of this book, you should feel comfortable with machine learning, at which point understanding where data comes from and how it's prepared becomes useful. After all we want to apply te things learned here to the real world, and that starts with real world data.\n",
    "\n",
    "It is still a bonus chapter and not required for understanding machine learning, but I found some suprising things when I cleaned this dataset. If you make it to the end, you really should read it.\n",
    ":::\n",
    "\n",
    "I've taken the liberty of further cleaning the data and making it accessible through a Python API so we can get right to work on machine learning and NLP.\n",
    "\n",
    "This book provides a conda environment file (see the [introduction](intro.qmd#what-this-book-is)) with everything you need to run the code. If you want to access the dataset without setting up the conda environment, you can get access to it through `pip`. If you're just following along through the book website then there's nothing you need to do.\n",
    "\n",
    "```{.bash code-line-numbers=\"false\"}\n",
    "$ pip install git+https://github.com/spenceforce/NLP-Simple-to-Spectacular\n",
    "```\n",
    "\n",
    "Let's get a feel for the datasets before we move on to machine learning. There are two movie review datasets available. One for classification and the other for unsupervised learning.\n",
    "\n",
    "## Classification dataset\n",
    "\n",
    "This dataset contains movie reviews and labels indicating if the review is positive (label 1) or negative (label 0). It is intended for benchmarking sentiment classification tasks. Sentiment classification is about predicting the feeling a text conveys. Like emotions such as happy, sad, or angry. In this case it's predicting whether a review says if a movie is good or bad.\n",
    "\n",
    "This dataset is split into a set for training and a set for testing. We can access both the train and test sets with `get_train_test_data`, which returns a `DataFrame` object for each set. The `DataFrame` class is a staple of [`pandas`](https://pandas.pydata.org/docs/). Dataframes are tables and they are not unique to `pandas`, but `pandas` is the de facto Python library for working with dataframes. You can think of dataframes as the programmatic version of an excel spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026e61c9-afc6-4ddf-880a-b635d005c406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlpbook import get_train_test_data\n",
    "\n",
    "train_df, test_df = get_train_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca64a2a-4156-428c-9d90-fa1920382502",
   "metadata": {},
   "source": [
    "`train_df` and `test_df` have the same format, so we'll just inspect `train_df`. We can see how many rows are in the dataframe and information about the columns with `DataFrame.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b853f6c-6d5a-48a4-8d23-a608224cb0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 24904 entries, 0 to 12499\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        24904 non-null  int64 \n",
      " 1   movie_id  24904 non-null  object\n",
      " 2   rating    24904 non-null  int64 \n",
      " 3   review    24904 non-null  object\n",
      " 4   label     24904 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69df7c5-9158-4c3f-961f-d9ee345a6f8d",
   "metadata": {},
   "source": [
    "`DataFrame.info()` says there are 24,904 rows. There are five columns, three of which have type `int64` and two with type `object`;[`pandas` assigns the type `object` to non-numeric values.]{.aside} the `object` types are strings in our dataframe.\n",
    "\n",
    "Each row is for one review. A brief rundown of what the columns are:\n",
    "\n",
    "- `id`: The review ID. For each label, this is a unique identifier for the review.\n",
    "- `movie_id`: The movie ID. Uniqe identifier for the movie the review is about.\n",
    "- `rating`: A score from 1-10 that the reviewer gave the movie.\n",
    "- `review`: This is the review. Pretty self-explanatory.\n",
    "- `label`: A 0 or 1 value indicating if the review is negative or positive, respectively.\n",
    "\n",
    "The columns we're interested in are `review`, `label`, and to a lesser extend, `rating`. `review` will be the input to all models as this is the natural language we are trying to process. `label` and `rating` are what we're trying to predict! We will mainly be predicting `label`, but we will also use `rating` to show how to scale binary classification (predicting two labels) to multiple labels (predicting three or more labels).\n",
    "\n",
    "Let's inspect a few reviews with `DataFrame.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8dc74ce-2047-44a9-b67b-2a264d6adcf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7275</td>\n",
       "      <td>tt0082799</td>\n",
       "      <td>1</td>\n",
       "      <td>\"National Lampoon Goes to the Movies\" (1981) i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1438</td>\n",
       "      <td>tt0397501</td>\n",
       "      <td>4</td>\n",
       "      <td>Well! What can one say? Firstly, this adaptati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9137</td>\n",
       "      <td>tt0364986</td>\n",
       "      <td>1</td>\n",
       "      <td>What can I say, this is a piece of brilliant f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>173</td>\n",
       "      <td>tt0283974</td>\n",
       "      <td>3</td>\n",
       "      <td>A decent sequel, but does not pack the punch o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8290</td>\n",
       "      <td>tt0314630</td>\n",
       "      <td>2</td>\n",
       "      <td>Alan Rudolph is a so-so director, without that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id   movie_id  rating                                             review  \\\n",
       "0  7275  tt0082799       1  \"National Lampoon Goes to the Movies\" (1981) i...   \n",
       "1  1438  tt0397501       4  Well! What can one say? Firstly, this adaptati...   \n",
       "2  9137  tt0364986       1  What can I say, this is a piece of brilliant f...   \n",
       "3   173  tt0283974       3  A decent sequel, but does not pack the punch o...   \n",
       "4  8290  tt0314630       2  Alan Rudolph is a so-so director, without that...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489deebc-8599-45dd-b1e2-099b115274fc",
   "metadata": {},
   "source": [
    "The `review` column looks like natural language and the `label` and `rating` columns have numeric values just like `DataFrame.info()` said.\n",
    "\n",
    "We can also see how this dataset is split by label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52f49a5-2e03-4810-b221-e1c46d1fbf2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "1    12472\n",
       "0    12432\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.value_counts(\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70238d58-f1eb-46f9-9c0a-200672b56e17",
   "metadata": {},
   "source": [
    "There are 12,472 positive labels and 12,432 negative labels. That's almost a 50/50 split.\n",
    "\n",
    "## Unsupervised dataset\n",
    "\n",
    "The train/test sets above have labels, 0 or 1, which allows them to be used in a _supervised_ learning fashion. In supervised learning we have real outputs, the review labels in this case, to compare to our machine learning model outputs. We can supervise the models learning by comparing it's outputs to the labels and let the model know how it's doing.\n",
    "\n",
    "Unsupervised learning is just input data. There's no label to use as a comparator. Instead the model must learn from the data without knowing whether it is right or wrong. This kind of learning is less about predicting a specific property and more about learning general properties of the data.\n",
    "\n",
    "This dataset is available through `get_unsup_data`. Let's inspect it with `DataFrame.info()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20a4a512-c06c-4c2a-8bfb-37e5013e0d11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 49507 entries, 0 to 49999\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        49507 non-null  int64 \n",
      " 1   movie_id  49507 non-null  object\n",
      " 2   review    49507 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "from nlpbook import get_unsup_data\n",
    "\n",
    "unsup_df = get_unsup_data()\n",
    "unsup_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5689c-c200-499b-a0a1-9a872820b3e8",
   "metadata": {},
   "source": [
    "As you can see, there is no `label` or `rating` columns. It's just reviews and nothing else.\n",
    "\n",
    "The next chapter will focus on building our first model. It will be simple and not very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ff99b8-63d5-4635-bb8a-07eeb11f4d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
