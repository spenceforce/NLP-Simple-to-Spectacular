{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afef2923-96a4-4a04-b84c-237b8dc26665",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"OneR, TwoR, RedR, BlueR\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93200d8f-e1b0-4aee-9efe-1e66b7d6d451",
   "metadata": {},
   "source": [
    "[Last chapter](../03_oner/oner.ipynb) we implemented the OneR [@Holte1993] algorithm. In this chapter we'll improve the model without improving the model. Sounds strange, but bear with me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fe5ed09-668e-4ffb-922a-1c6aed2aebd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 3]\n",
      "[2 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "for x in a.T:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d41ef502-1561-466a-acc8-69efdff379c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, TransformerMixin\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "#class BagOfLetters(TransformerMixin, BaseEstimator):\n",
    "    \n",
    "\n",
    "class OneR(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the model with inputs `X` on labels `y`.\"\"\"\n",
    "        best_predictors = None\n",
    "        best_i = None\n",
    "        best_score = float('-inf')\n",
    "        self.fallback_ = DummyClassifier().fit(X, y)\n",
    "        # Added fallback for missing categories.\n",
    "        X, y = np.array(X), np.array(y)\n",
    "        for i, x in enumerate(X.T):\n",
    "            predictors = {}\n",
    "            for x_val in np.unique(x):\n",
    "                is_x = x == x_val\n",
    "                predictors[x_val] = DummyClassifier().fit(x[is_x], y[is_x])\n",
    "\n",
    "            self.predictors_ = predictors\n",
    "            self.i_ = i\n",
    "            score = self.score(X, y)\n",
    "            if score > best_score:\n",
    "                best_predictors = predictors\n",
    "                best_i = i\n",
    "                best_score = score\n",
    "\n",
    "        self.predictors_ = best_predictors\n",
    "        self.i_ = best_i\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for inputs `X`.\"\"\"\n",
    "        X = np.array(X)\n",
    "        rv = []\n",
    "        for x in X[:, self.i_]:\n",
    "            try:\n",
    "                rv.append(self.predictors_[x].predict([x])[0])\n",
    "            except KeyError:\n",
    "                rv.append(self.fallback_.predict([x])[0])\n",
    "                # Use the fallback when the category isn't \n",
    "                # in `self.predictors_`.\n",
    "        return np.array(rv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "24ee916b-eab6-42c4-9370-f6c690353a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ' '.' '?' 'A' 'I' 'T' 'c' 'd' 'e' 'f' 'h' 'i' 'm' 'n' 'o' 'r' 's' 't'\n",
      " 'u']\n",
      "[[4 1 0 0 0 1 1 1 2 1 2 3 1 1 1 1 3 3 1]\n",
      " [5 1 0 0 0 1 3 3 4 0 2 2 2 3 3 0 3 3 2]\n",
      " [5 1 0 1 0 0 0 2 2 0 3 3 0 2 1 1 2 3 0]\n",
      " [4 0 1 0 1 0 1 1 2 1 2 2 1 1 1 1 3 4 1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "class BagOfLetters(CountVectorizer):\n",
    "    def build_tokenizer(self):\n",
    "        return list\n",
    "vectorizer = CountVectorizer(analyzer=\"char\", lowercase=False)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(X.toarray())\n",
    "#vectorizer2 = CountVectorizer(analyzer='word', ngram_range=(2, 2))\n",
    "#X2 = vectorizer2.fit_transform(corpus)\n",
    "#vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31ee622c-fd81-4f2c-a708-7e2be3dde2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'movie_id', 'rating', 'review', 'label'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpbook import get_train_test_data\n",
    "\n",
    "train_df, test_df = get_train_test_data()\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abd16c06-12cd-46cf-b16e-a7879c5e5ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 1180459 stored elements and shape (24904, 178)>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"char\", lowercase=False)\n",
    "X_train = vectorizer.fit_transform(train_df[\"review\"])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d2ca938-3716-408b-91a7-4edce581759b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6d44a032-12a8-4e17-af98-5170b0288550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\x08', '\\t', '\\x10', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(',\n",
       "       ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5',\n",
       "       '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', '@', 'A', 'B',\n",
       "       'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O',\n",
       "       'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', '\\\\',\n",
       "       ']', '^', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
       "       'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v',\n",
       "       'w', 'x', 'y', 'z', '{', '|', '}', '~', '\\x80', '\\x84', '\\x85',\n",
       "       '\\x8d', '\\x8e', '\\x91', '\\x95', '\\x96', '\\x97', '\\x9a', '\\x9e',\n",
       "       '\\xa0', '¡', '¢', '£', '¤', '¦', '§', '¨', '«', '\\xad', '®', '°',\n",
       "       '³', '´', '·', 'º', '»', '½', '¾', '¿', 'À', 'Á', 'Ã', 'Ä', 'Å',\n",
       "       'È', 'É', 'Ê', 'Õ', 'Ø', 'Ü', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å',\n",
       "       'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò',\n",
       "       'ó', 'ô', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ý', 'ō', '–', '‘', '’',\n",
       "       '“', '”', '…', '₤', '\\uf0b7'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7452334-821e-4f60-afa3-fb454872392c",
   "metadata": {},
   "outputs": [],
   "source": [
    "oner = OneR().fit(X_train.toarray(), train_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f048bb3-6d0a-4bee-b665-0ad6baca755d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5812817904374364"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oner.score(vectorizer.transform(test_df[\"review\"]).toarray(), test_df[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a0921b09-05a4-4bb4-b56b-6d1f5dec5af3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oner.i_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "752fa091-309d-4c9b-a1a4-b6f8d9c33727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'?'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()[oner.i_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db280fb-4f48-4837-9662-02de170d09c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
