{
 "cells": [
  {
   "cell_type": "raw",
   "id": "afef2923-96a4-4a04-b84c-237b8dc26665",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"OneR, TwoR, RedR, BlueR: Inputs matter\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93200d8f-e1b0-4aee-9efe-1e66b7d6d451",
   "metadata": {},
   "source": [
    "[Last chapter](../03_oner/oner.ipynb) we implemented the OneR [@Holte1993] algorithm. In this chapter we'll improve the model without improving the model. Sounds strange, but bear with me. This chapter is all about changing the input to the model.\n",
    "\n",
    "Right now we just pass in the review as input. It's a string and every review is unique. The review is treated as a category where each unique review is it's own category. Before training, each unique review is assigned a number to represent it.\n",
    "\n",
    "With this setup, the only way to compare two reviews is to see if they are the same review or not. But two pieces of text contain much richer information that can be used to compare them. Letters make up words, words make up sentences, sentences make up paragraphs, and so on. Language also has syntax and semantics. As machine learning practitioners we actually don't care about syntax and semantics. We expect our models will learn the concepts they need as they train on the target task. We do care about how the text is represented as this is what our models learn from. Our model currently learns from a single number that represents a review. Let's change that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b9574-f8d0-4042-acba-886123280046",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    "\n",
    "Feature extraction is a way to convert data into a format that is useable by machine learning models. Data that is numeric, like scientific measurements, are machine learning friendly by default, but text and image data is not. These types of data need to be converted to numbers in a way that preserves their information. Last chapter we converted our text data to numbers, but we didn't preserve any of the information in the reviews and ended up with a model that performed the same as the baseline.\n",
    "\n",
    "We'll try again, but while preserving some of the information in the text. As always, let's start simple.\n",
    "\n",
    "### Bag of characters\n",
    "\n",
    "We have reviews. These are just sentences, which are just words, which are just characters. So reviews are characters. We can count the number of each character in a review and represent the review as character counts. This is representation is called a bag of characters and it can be extended to words, sentences, or whatever you want really. And of course `sklearn` has a way to do this.[`CountVectotrizer` returns a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/sparse.html) which are memory efficient for matrices that contain mostly 0s.]{.aside}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a9c5a2-74ac-47ce-98b2-9db658890d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, 275,   0,   6,   0,   0,   0,   1,   5,   1,   1,\n",
       "          0,   0,  25,   4,  16,   8,   0,   2,   0,   0,   0,   0,   0,\n",
       "          0,   1,   2,   0,   0,   8,   0,   8,   0,   0,   2,   5,   0,\n",
       "          1,   0,   0,   3,   2,   3,   0,   0,   3,   5,   2,   1,   1,\n",
       "          0,   2,   1,   5,   1,   0,   3,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  99,  24,  23,  50, 166,  31,  21,  64,  84,   1,\n",
       "          5,  61,  27,  89,  92,  30,   1,  94,  90, 122,  29,  13,  17,\n",
       "          0,  35,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nlpbook import get_train_test_data\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "train_df, test_df = get_train_test_data()\n",
    "\n",
    "# Create the bag of characters feature extraction transformer.\n",
    "# The `CountVectorizer` class bags input text. We set\n",
    "# `analyzer=\"char\"` so that `CountVectorizer` counts characters\n",
    "# instead of words and `lowercase=False` to prevent upper case\n",
    "# letters from being converted to lowercase.\n",
    "vectorizer = CountVectorizer(analyzer=\"char\", lowercase=False)\n",
    "\n",
    "# Fit the bag of characters transformer on our reviews.\n",
    "# Notice we do not pass a matrix into the fit method, but an array.\n",
    "# Feature extraction should be performed on a per column basis so\n",
    "# we need to pass in the column we want feature extraction performed\n",
    "# on.\n",
    "vectorizer.fit(train_df[\"review\"])\n",
    "\n",
    "# Transform the first row to a bag of characters.\n",
    "# Convert the sparse matrix to a numpy array to see the counts.\n",
    "vectorizer.transform(train_df[\"review\"].head(1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d8ed55-3b53-425a-95a8-0fe924687df1",
   "metadata": {},
   "source": [
    "We can check what character each array element is counting with the `vocabulary_` dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1892adc-36f1-448c-98e8-cfbba1393ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('\"', 5), ('N', 49), ('a', 68), ('t', 87), ('i', 76)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.vocabulary_.items())[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb25bf1-fd4d-4087-9410-64a973c926c5",
   "metadata": {},
   "source": [
    "So index 5 of the above array is the counts for the character `\"` and index 49 is the counts for `N`.\n",
    "\n",
    "## OneR revisited\n",
    "\n",
    "Now we can just pass this as input to our OneR model right? Not quite, our model isn't capable of handling this input yet. Here's the implementation from last chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55fc1448-812f-40bd-8ba8-750aa07e65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.utils.validation import validate_data\n",
    "\n",
    "\n",
    "class OneR(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Find the most predictive rule.\"\"\"\n",
    "        # Sanity check on `X` and `y`.\n",
    "        X, y = validate_data(self, X, y)\n",
    "        predictors = {}\n",
    "        # Get the unique categories from the first column.\n",
    "        categories = np.unique(X[:, 0])\n",
    "        for category in categories:\n",
    "            # Create a conditional array where each index\n",
    "            # is a boolean indicating if that index in the\n",
    "            # first column of `X` is the category we're iterating\n",
    "            # over.\n",
    "            is_category = X[:, 0] == category\n",
    "            # Grab all data points and labels in this category.\n",
    "            _X = X[is_category]\n",
    "            _y = y[is_category]\n",
    "            # Train a baseline classifier on the category.\n",
    "            predictors[category] = DummyClassifier().fit(_X, _y)\n",
    "        self.predictors_ = predictors\n",
    "        # Create a fallback predictor for unknown categories.\n",
    "        self.unknown_predictor_ = DummyClassifier().fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for inputs `X`.\"\"\"\n",
    "        # Sanity check on `X`.\n",
    "        # `reset` should be `True` in `fit` and `False` everywhere else.\n",
    "        X = validate_data(self, X, reset=False)\n",
    "        # Create an empty array that will hold the predictions.\n",
    "        rv = np.zeros(X.shape[0])\n",
    "        # Get the unique categories from the first column.\n",
    "        categories = np.unique(X[:, 0])\n",
    "        for category in categories:\n",
    "            # Create a conditional array where each index\n",
    "            # is a boolean indicating if that index in the\n",
    "            # first column of `X` is the category we're iterating\n",
    "            # over.\n",
    "            is_category = X[:, 0] == category\n",
    "            # Grab all data points in this category.\n",
    "            _X = X[is_category]\n",
    "            # Predict the label for all datapoints in `_X`.\n",
    "            try:\n",
    "                predictions = self.predictors_[category].predict(_X)\n",
    "            except KeyError:\n",
    "                # Fallback to the predictor for unknown categories.\n",
    "                predictions = self.unknown_predictor_.predict(_X)\n",
    "            # Assign the prediction for this category to\n",
    "            # the corresponding indices in `rv`.\n",
    "            rv[is_category] = predictions\n",
    "        return rv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bd4fd7-75e4-4c0a-9e94-77ffc805da36",
   "metadata": {},
   "source": [
    "Notice the model only looks at the first column. If we use it now it will use the counts in the first column of our bag of characters matrix for training and prediction which isn't what we want.\n",
    "\n",
    "Previously, I said the algorithm works by predicting the most frequent label for each category, but in reality it only does this for _one feature_, hence the name OneR which stands for One Rule. The model finds the feature whose categories are most predictive of the training data, then predicts labels based on just that feature. When we first implemented this model we only had one feature so it didn't matter, but now we have many, so we need to tweak the implementation to find the best feature when given any number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "977b9412-fdfc-4f02-8dce-4e33d5f8bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "# Rename the `OneR` class to `Rule`.\n",
    "Rule = OneR\n",
    "\n",
    "\n",
    "# Create a new `OneR` class which finds the best `Rule` in the\n",
    "# dataset.\n",
    "class OneR(ClassifierMixin, BaseEstimator):\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Find the best rule in the dataset.\"\"\"\n",
    "        # Sanity check on `X` and `y`.\n",
    "        X, y = validate_data(self, X, y, accept_sparse=True)\n",
    "\n",
    "        col_idx = score = rule = None\n",
    "        # Iterate over the indices for each column in X.\n",
    "        for i in range(X.shape[1]):\n",
    "            # Create a new matrix containing just the ith column.\n",
    "            _X = X[:, [i]]\n",
    "            # Convert sparse matrix to `numpy` array.\n",
    "            # `Rule` works on numpy arrays, so we should use consistent\n",
    "            # array types.\n",
    "            if scipy.sparse.issparse(_X):\n",
    "                _X = _X.toarray()\n",
    "\n",
    "            # Create a rule for the ith column.\n",
    "            rule_i = Rule().fit(_X, y)\n",
    "            # Score the ith columns accuracy.\n",
    "            score_i = rule_i.score(_X, y)\n",
    "\n",
    "            # Keep the rule for the ith column if it has the highest\n",
    "            # accuracy so far.\n",
    "            if score is None or score_i > score:\n",
    "                rule = rule_i\n",
    "                score = score_i\n",
    "                col_idx = i\n",
    "\n",
    "        self.rule_ = rule\n",
    "        self.i_ = col_idx\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the labels for inputs `X`.\"\"\"\n",
    "        # Sanity check on `X`.\n",
    "        X = validate_data(self, X, reset=False, accept_sparse=True)\n",
    "        _X = X[:, [self.i_]]\n",
    "        # Convert sparse matrix to `numpy` array.\n",
    "        # `Rule` works on numpy arrays, so we should use consistent\n",
    "        # array types.\n",
    "        if scipy.sparse.issparse(_X):\n",
    "            _X = _X.toarray()\n",
    "\n",
    "        # Return predictions for the rule.\n",
    "        return self.rule_.predict(_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e4d689-7a55-452f-8616-cbb2a1e7a92c",
   "metadata": {},
   "source": [
    "And now we can train the model! [[`ColumnTransformer`](https://scikit-learn.org/stable/modules/generated/sklearn.compose.ColumnTransformer.html) is a handy utility for applying transforms to specific columns of a dataframe.]{.aside}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "471abf36-f1a1-477c-a736-90b4a65db906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;bag_chars&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;bag_of_chars&#x27;,\n",
       "                                                  CountVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                  lowercase=False),\n",
       "                                                  &#x27;review&#x27;)])),\n",
       "                (&#x27;oner&#x27;, OneR())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Pipeline</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;bag_chars&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;bag_of_chars&#x27;,\n",
       "                                                  CountVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                                  lowercase=False),\n",
       "                                                  &#x27;review&#x27;)])),\n",
       "                (&#x27;oner&#x27;, OneR())])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>bag_chars: ColumnTransformer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for bag_chars: ColumnTransformer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;bag_of_chars&#x27;,\n",
       "                                 CountVectorizer(analyzer=&#x27;char&#x27;,\n",
       "                                                 lowercase=False),\n",
       "                                 &#x27;review&#x27;)])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>bag_of_chars</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>review</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CountVectorizer</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(analyzer=&#x27;char&#x27;, lowercase=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>OneR</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>OneR()</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('bag_chars',\n",
       "                 ColumnTransformer(transformers=[('bag_of_chars',\n",
       "                                                  CountVectorizer(analyzer='char',\n",
       "                                                                  lowercase=False),\n",
       "                                                  'review')])),\n",
       "                ('oner', OneR())])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | output: false\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Grab `X` and `y`.\n",
    "features = [\"review\"]\n",
    "labels = \"label\"\n",
    "X, y = train_df[features], train_df[labels]\n",
    "\n",
    "# Create the bag of characters transform.\n",
    "bag_of_chars = CountVectorizer(analyzer=\"char\", lowercase=False)\n",
    "\n",
    "# Wrap the bag of characters transform in a `ColumnTransformer`.\n",
    "# This class lets us perform transforms on specific columns of a\n",
    "# `DataFrame` instead of on the entire `DataFrame`. This allows\n",
    "# us to use `CountVectorizer` on just the \"review\" column.\n",
    "# Check the docs link in the margin.\n",
    "column_transform = ColumnTransformer(\n",
    "    [(\"bag_of_chars\", bag_of_chars, \"review\")]\n",
    ")\n",
    "\n",
    "oner = OneR()\n",
    "\n",
    "# Create our pipeline.\n",
    "pipeline = Pipeline([(\"bag_chars\", column_transform), (\"oner\", oner)])\n",
    "\n",
    "# Train it!\n",
    "pipeline.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0194628a-ddf7-4663-b292-45cb33570569",
   "metadata": {},
   "source": [
    "Now after all that work, how'd we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "170d1dfe-dcea-4fa5-9f14-68dcba741a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5812817904374364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, y_test = test_df[features], test_df[labels]\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bf0ea4-88db-4525-8f39-efbe397a03d8",
   "metadata": {},
   "source": [
    "58% accuracy, that's a big improvement over the 50% accuracy of our baseline and original OneR models! All we did was change the input to the OneR model and we gained an 8% bump in accuracy.\n",
    "\n",
    "## Machine learning is an end to end process\n",
    "\n",
    "We barely touched the model and ended up with an 8% improvement just by improving the preprocessing step. There are multiple steps to building a model, from collecting data through model training and they are all important for the final outcome. I probably sound like a broken record at this point, but this is why we started with a baseline model. The process of building a model is really one of experimentation. You make a change here then test it. Now a change there and test it. It's tweak after tweak, but you need to know how those tweaks affect the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e345bd59-9b6b-4167-9423-760baaba898e",
   "metadata": {},
   "source": [
    "## Models as analysis tools\n",
    "\n",
    "Now that we've trained a model that actually has some predictive power, we can start to use it for interesting things. Often we use models to predict outcomes, but we can also go in the other direction and use them to learn about our data. OneR found some character that is predictive for our data. What is that character?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "919b257a-0743-4d82-9354-4305f9585ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the index of the rule.\n",
    "bag_idx = oner.i_\n",
    "\n",
    "# Grab the vocabulary from the fitted bag of characters.\n",
    "vocab = column_transform.named_transformers_.bag_of_chars.vocabulary_\n",
    "\n",
    "# Find the character associated with the index.\n",
    "[char for char, char_idx in vocab.items() if char_idx == bag_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc17a5e-1e00-4874-90d5-0f301626e618",
   "metadata": {},
   "source": [
    "Interesting, question marks are the most important character for determining labels. My hypothesis is more question marks means a bad review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd6ddb47-7ff6-4ea0-9a49-9f5d6ec46eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='?', ylabel='count'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "data = X_test.copy()\n",
    "data[\"?\"] = column_transform.transform(X_test)[:, bag_idx].toarray()\n",
    "data[\"label\"] = y_test\n",
    "sns.countplot(data, x=\"?\", hue=\"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5c72a5-600f-4cdb-bb60-34a515992372",
   "metadata": {},
   "source": [
    "Ah, so if there are no question marks, the review is more likely to be positive. Inversely we can say if the review contains a question, it's likely the review is negative.\n",
    "\n",
    "Instead of analyzing the data ourselves to find which characters are associated with positive or negative reviews, our model did the analysis for us. We let the model learn about the data, then in turn we leveraged what the model learned to gain an insight into the data. As we make better models and richer representations of the input text, the amount of information we'll learn about the data will increase as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cae2743a-6da1-41e4-b365-69114f8d9fbe",
   "metadata": {},
   "source": [
    "## Rolling our own feature extractor\n",
    "\n",
    "We've already handled the OneR model, now let's make a bag of characters transformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaf2ff2f-ef6e-4a8d-b3cf-a54f4dbeeb56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5812817904374364"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class BagOfChars(TransformerMixin, BaseEstimator):\n",
    "    \"\"\"Bag of characters feature extractor.\"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit on all characters in the array `X`.\n",
    "\n",
    "        Note: `X` should be a 1d array.\n",
    "        \"\"\"\n",
    "        # We run our own validation check since `validate_data`\n",
    "        # expects a 2d numberic array.\n",
    "        # We want a 1d text array so we'll check its shape here.\n",
    "        # While iterating over the array values we'll check\n",
    "        # they are text while trying to extract characters.\n",
    "        assert len(X.shape) == 1\n",
    "\n",
    "        vocabulary_ = {}\n",
    "        # Iterate over each string in the array.\n",
    "        for x in X:\n",
    "            # Check it's a string!\n",
    "            assert isinstance(x, str)\n",
    "            # Get the unique characters in the string.\n",
    "            chars = np.unique(list(x))\n",
    "            # Add each character to the vocabulary if it isn't\n",
    "            # there already.\n",
    "            for char in chars:\n",
    "                if char not in vocabulary_:\n",
    "                    vocabulary_[char] = len(vocabulary_)\n",
    "        self.vocabulary_ = vocabulary_\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform `X` to a count matrix.\n",
    "\n",
    "        Note: `X` should be a 1d array.\n",
    "        \"\"\"\n",
    "        # Run our own checks.\n",
    "        assert len(X.shape) == 1\n",
    "        # Check we fit the instance.\n",
    "        assert hasattr(self, \"vocabulary_\")\n",
    "\n",
    "        # Create a matrix to hold the counts.\n",
    "        rv = np.zeros((X.shape[0], len(self.vocabulary_)))\n",
    "        # Iterate over each string in the array.\n",
    "        for i, x in enumerate(X):\n",
    "            # Check it's a string!\n",
    "            assert isinstance(x, str)\n",
    "            # Get the unique characters in the string and their\n",
    "            # counts.\n",
    "            chars, counts = np.unique(list(x), return_counts=True)\n",
    "            # Add each character count to the count matrix\n",
    "            # for the specific row.\n",
    "            for char, count in zip(chars, counts):\n",
    "                # Make sure the character is part of the vocabulary,\n",
    "                # otherwise ignore it.\n",
    "                if char in self.vocabulary_:\n",
    "                    rv[i, self.vocabulary_[char]] = count\n",
    "        # Return the count matrix.\n",
    "        return rv\n",
    "\n",
    "\n",
    "# Let's plug it into the pipeline and see how it goes.\n",
    "column_transform = ColumnTransformer(\n",
    "    [(\"bag_of_chars\", BagOfChars(), \"review\")]\n",
    ")\n",
    "\n",
    "oner = OneR()\n",
    "\n",
    "# Create our pipeline.\n",
    "pipeline = Pipeline([(\"bag_chars\", column_transform), (\"oner\", oner)])\n",
    "\n",
    "# Train it!\n",
    "pipeline.fit(X, y)\n",
    "pipeline.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0579cf7-7050-441a-801a-5268f6d64258",
   "metadata": {},
   "source": [
    "Easy peasy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d842e1fa-0080-4c85-bf52-0a81e46106ea",
   "metadata": {},
   "source": [
    "## Multiclass classification\n",
    "\n",
    "Let's see how we do with multiclass classification. Our accuracy with the baseline model was 20%. Can we beat that?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a57239-f097-4c78-a8fe-a93f4f75955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19377416073245168"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_multi = train_df[\"rating\"]\n",
    "y_test_multi = test_df[\"rating\"]\n",
    "\n",
    "pipeline.fit(X, y_multi)\n",
    "pipeline.score(X_test, y_test_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36104207-f79f-4a14-a3af-98317cc62724",
   "metadata": {},
   "source": [
    "It's about the same, that's unfortunate. This is a harder problem than predicting if a review is positive or negative. The decision of what class to choose is more complicated since there's more options to choose from. With that added complexity, the model needs to learn more information about the data to be predictive. This means our model is either too simple or the input doesn't contain enough information to scale to this more difficult task. Performance on the multiclass classification problem will lag behind the binary classification problem, but it will improve as we build better and better models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
